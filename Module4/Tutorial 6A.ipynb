{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 6: Part A\n",
    "\n",
    "There are four ways to merge/combine between different DataFrames in pandas: concatenating, appending, merging and joining. Each has its own use cases and best practice. We discussed in Tutorial 5 the both methods of Concatenating and appending. In this tutorial, we discuss both merge and join. \n",
    "\n",
    "## Methods for integrating data with Pandas:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "## 3. Merge:\n",
    "\n",
    "Concat and append have limited capabilities in joining tables through keys and considering the inter-relationship between tables. Merge and join on the other hand combine DataFrames based on a key. According to concepts of relational databases like SQL, there are three types of relationships between tables:\n",
    "\n",
    "1.\t**One-to-one:** When each primary key value relates to only one (or no) record in the related table.\n",
    "\n",
    "2.\t**One-to-many:** When the primary key table contains only one record that relates to none, one, or many records in the related table.\n",
    "\n",
    "3.\t**Many-to-many:** When each record in both tables can relate to any number of records (or no records) in the other table.\n",
    "\n",
    "We will discuss in the following how merge manages the three types of relationships. The following is an example of using merge for one-to-many relationship between table respresnts customer details and shopping history for each customer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_ID First_Name Last_Name\n",
      "0           1         A1        B1\n",
      "1           2         A2        B2\n",
      "2           3         A3        B3\n",
      "3           4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           4         A4        B4        400    Milk\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "customers= pd.DataFrame({'Customer_ID': ['1', '2', '3', '4'],\n",
    "                      'First_Name': ['A1','A2','A3','A4'],\n",
    "                    'Last_Name': ['B1', 'B2', 'B3', 'B4']})\n",
    "shopping_history= pd.DataFrame({'Customer_ID': ['1', '1', '1', '4','5'],\n",
    "                            'Product_ID':['100','200','300','400','500'],\n",
    "                      'product': ['Oil','Sugar','Tea','Milk','Eggs']})\n",
    "merged_df= pd.merge(customers,shopping_history)\n",
    "print customers\n",
    "print shopping_history\n",
    "print merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try to change Customer_ID to another name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Product_ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-87c00dbe2d45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmerged_df\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustomers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshopping_history\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Product_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mmerged_df\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m     36\u001b[0m                          \u001b[0mright_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_on\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mleft_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m                          \u001b[0mright_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mright_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msuffixes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                          copy=copy, indicator=indicator)\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator)\u001b[0m\n\u001b[1;32m    208\u001b[0m         (self.left_join_keys,\n\u001b[1;32m    209\u001b[0m          \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m          self.join_names) = self._get_merge_keys()\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/tools/merge.pyc\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    441\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m                         \u001b[0mright_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m                     \u001b[0mleft_keys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m                     \u001b[0mjoin_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0m_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft_on\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1995\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1997\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1999\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_getitem_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36m_getitem_column\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2002\u001b[0m         \u001b[0;31m# get column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2003\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_unique\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2004\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0;31m# duplicate columns & possible reduce dimensionality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1348\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mres\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_box_item_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, item, fastpath)\u001b[0m\n\u001b[1;32m   3288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3289\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3290\u001b[0;31m                 \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3291\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3292\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0misnull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/carolinegao/anaconda2/lib/python2.7/site-packages/pandas/indexes/base.pyc\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   1945\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1946\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1947\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1948\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1949\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4154)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/index.pyx\u001b[0m in \u001b[0;36mpandas.index.IndexEngine.get_loc (pandas/index.c:4018)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12368)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/hashtable.pyx\u001b[0m in \u001b[0;36mpandas.hashtable.PyObjectHashTable.get_item (pandas/hashtable.c:12322)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Product_ID'"
     ]
    }
   ],
   "source": [
    "merged_df= pd.merge(customers,shopping_history, on=\"Product_ID\")\n",
    "print merged_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that if the key is not specified, merge uses the overlapping column names as the keys. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to merge:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When there are no common columns between the DataFrames, you need to specify the key to merge on. Use on, left_on and right_on attributes to define the key in DataFrames. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CID First_Name Last_Name\n",
      "0   1         A1        B1\n",
      "1   2         A2        B2\n",
      "2   3         A3        B3\n",
      "3   4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  CID First_Name Last_Name Customer_ID Product_ID product\n",
      "0   1         A1        B1           1        100     Oil\n",
      "1   1         A1        B1           1        200   Sugar\n",
      "2   1         A1        B1           1        300     Tea\n",
      "3   4         A4        B4           4        400    Milk\n"
     ]
    }
   ],
   "source": [
    "customers2= pd.DataFrame({'CID': ['1', '2', '3', '4'],\n",
    "                      'First_Name': ['A1','A2','A3','A4'],\n",
    "                    'Last_Name': ['B1', 'B2', 'B3', 'B4']})\n",
    "merged_onkey= pd.merge(customers2,shopping_history,left_on='CID',right_on='Customer_ID')\n",
    "print customers2 \n",
    "print shopping_history\n",
    "print merged_onkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The default \"how\" setting for merge is 'inner'!\n",
    "\n",
    "\n",
    "In the joined table, some records are deleted because they do not have a corresponding record in the original DataFrame (such as customer 2,3,5 and Eggs). This happens because the deafult method for merging is the inner join. For zero information loss, you can use outer join instead. The outer join could be full outer (getting full information from both DataFrames), left (only from the left DataFrame) or right (using left, right methods). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Customer_ID First_Name Last_Name\n",
      "0           1         A1        B1\n",
      "1           2         A2        B2\n",
      "2           3         A3        B3\n",
      "3           4         A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           2         A2        B2        NaN     NaN\n",
      "4           3         A3        B3        NaN     NaN\n",
      "5           4         A4        B4        400    Milk\n",
      "6           5        NaN       NaN        500    Eggs\n",
      "  Customer_ID First_Name Last_Name Product_ID product\n",
      "0           1         A1        B1        100     Oil\n",
      "1           1         A1        B1        200   Sugar\n",
      "2           1         A1        B1        300     Tea\n",
      "3           2         A2        B2        NaN     NaN\n",
      "4           3         A3        B3        NaN     NaN\n",
      "5           4         A4        B4        400    Milk\n",
      "  Customer_ID Product_ID product First_Name Last_Name\n",
      "0           1        100     Oil         A1        B1\n",
      "1           1        200   Sugar         A1        B1\n",
      "2           1        300     Tea         A1        B1\n",
      "3           4        400    Milk         A4        B4\n",
      "4           2        NaN     NaN         A2        B2\n",
      "5           3        NaN     NaN         A3        B3\n"
     ]
    }
   ],
   "source": [
    "print customers\n",
    "print shopping_history\n",
    "merged_outer= pd.merge(customers,shopping_history, how='outer')\n",
    "print merged_outer\n",
    "merged_left= pd.merge(customers,shopping_history, how='left')\n",
    "print merged_left\n",
    "merged_right= pd.merge(shopping_history,customers, how='right')\n",
    "print merged_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Many-to-many merge:\n",
    "A more complicated relationship to manage using merge method is the many-to-many. Consider the example of customers and products. The customer DataFrame contains information about customers, while products has details about differnt grocery items. One customer can buy non or many products, and any product can be purchased by non or many customers. Pandas manage this relationship using merge method. Like SQL's JOIN clause, pandas.merge allows two DataFrames to be joined on one or more keys. The function provides a series of parameters (on, left_on, right_on, left_index, right_index) allowing you to specify the columns or indexes on which to join. In version 0.17.0. Pandas added the argument indicator. If True, a Categorical-type column called _merge will be added to the output object that takes on values. Here is a simple example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d1 key\n",
      "0   0   a\n",
      "1   1   a\n",
      "2   2   b\n",
      "3   3   c\n",
      "4   4   a\n",
      "5   5   b\n",
      "6   6   c\n",
      "   d1 key\n",
      "0   0   d\n",
      "1   1   d\n",
      "2   2   b\n",
      "3   3   b\n",
      "4   4   b\n",
      "5   5   a\n",
      "     d1 key        True\n",
      "0   0.0   a   left_only\n",
      "1   1.0   a   left_only\n",
      "2   2.0   b        both\n",
      "3   3.0   c   left_only\n",
      "4   4.0   a   left_only\n",
      "5   5.0   b   left_only\n",
      "6   6.0   c   left_only\n",
      "7   0.0   d  right_only\n",
      "8   1.0   d  right_only\n",
      "9   3.0   b  right_only\n",
      "10  4.0   b  right_only\n",
      "11  5.0   a  right_only\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.DataFrame({'key': ['a', 'a', 'b', 'c', 'a', 'b','c'], 'd1': range(7)})\n",
    "df2 = pd.DataFrame({'key': ['d', 'd', 'b', 'b', 'b', 'a'], 'd1': range(6)})\n",
    "print df1\n",
    "print df2\n",
    "merge= pd.merge(df1,df2, how='outer',indicator='True')\n",
    "print merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d1 key\n",
      "0   0   a\n",
      "1   1   a\n",
      "2   2   b\n",
      "3   3   c\n",
      "4   4   a\n",
      "5   5   b\n",
      "6   6   c\n",
      "   d1 key\n",
      "0   0   d\n",
      "1   1   d\n",
      "2   2   b\n",
      "3   3   b\n",
      "4   4   b\n",
      "5   5   a\n",
      "   d1 key_x key_y       True\n",
      "0   0     a     d       both\n",
      "1   1     a     d       both\n",
      "2   2     b     b       both\n",
      "3   3     c     b       both\n",
      "4   4     a     b       both\n",
      "5   5     b     a       both\n",
      "6   6     c   NaN  left_only\n"
     ]
    }
   ],
   "source": [
    "print df1\n",
    "print df2\n",
    "merge= pd.merge(df1,df2, how='outer',indicator='True', on='d1')\n",
    "print merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   d1 key\n",
      "0   0   a\n",
      "1   1   a\n",
      "2   2   b\n",
      "3   3   c\n",
      "4   4   a\n",
      "5   5   b\n",
      "6   6   c\n",
      "   d1 key\n",
      "0   0   d\n",
      "1   1   d\n",
      "2   2   b\n",
      "3   3   b\n",
      "4   4   b\n",
      "5   5   a\n",
      "   d1 key_x key_y       True\n",
      "0   0     a     d       both\n",
      "1   1     a     d       both\n",
      "2   2     b     b       both\n",
      "3   3     c     b       both\n",
      "4   4     a     b       both\n",
      "5   5     b     a       both\n",
      "6   6     c   NaN  left_only\n"
     ]
    }
   ],
   "source": [
    "print df1\n",
    "print df2\n",
    "merge= pd.merge(df1,df2, how='outer',indicator='True', on='d1')\n",
    "print merge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In cases that there is a meaningful index in one of the columns, this index can replace the original DataFrame index. By default, set index returns a new DataFrame, so you will have to specify if you would like the changes to occur in place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n"
     ]
    }
   ],
   "source": [
    "customers.set_index('Customer_ID', inplace=True)\n",
    "shopping_history.set_index('Customer_ID', inplace=True)\n",
    "print customers\n",
    "print shopping_history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Join:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The DataFrame also has a convenient join method for merging on the index. This is used when you have objects with similar row labels, but different columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "            Product_ID product\n",
      "Customer_ID                   \n",
      "1                  100     Oil\n",
      "1                  200   Sugar\n",
      "1                  300     Tea\n",
      "4                  400    Milk\n",
      "5                  500    Eggs\n",
      "            First_Name Last_Name Product_ID product\n",
      "Customer_ID                                        \n",
      "1                   A1        B1        100     Oil\n",
      "1                   A1        B1        200   Sugar\n",
      "1                   A1        B1        300     Tea\n",
      "2                   A2        B2        NaN     NaN\n",
      "3                   A3        B3        NaN     NaN\n",
      "4                   A4        B4        400    Milk\n",
      "5                  NaN       NaN        500    Eggs\n"
     ]
    }
   ],
   "source": [
    "joined= customers.join(shopping_history,how=\"outer\")\n",
    "print customers\n",
    "print shopping_history\n",
    "print joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## * Combining data with overlap: \n",
    "\n",
    "We use this method when we want to “patch” values in one object from values for matching indices in the other.  Note that this method only takes values from the right DataFrame if they are missing in the left DataFrame. Consider the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0   1    2\n",
      "0  1.0   3  NaN\n",
      "1  NaN  10  NaN\n",
      "2  NaN   5  3.0\n",
      "      0    1    2\n",
      "0  10.0  NaN  4.0\n",
      "1   NaN  5.0  3.0\n",
      "2   2.0  4.0  NaN\n",
      "     0   1    2\n",
      "0  1.0   3  4.0\n",
      "1  NaN  10  3.0\n",
      "2  2.0   5  3.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "data1= pd.DataFrame([[1,3,np.nan],[np.nan,10,np.nan],[np.nan,5,3]])\n",
    "data2= pd.DataFrame([[10,np.nan,4],[np.nan,5,3],[2,4,np.nan]])\n",
    "print data1\n",
    "print data2\n",
    "data= data1.combine_first(data2)\n",
    "print data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data Reshaping: \n",
    "\n",
    "### Hirarical indexing : Stack and unstack \n",
    "\n",
    "Hirarical indexing provides a more structure way of presenting tabular data. There are two main methods for pivoting data with hirarical indexing. \n",
    "\n",
    "* stack: this “rotates” or pivots from the columns in the data to the rows\n",
    "* unstack: this pivots from the rows into the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     A         B\n",
      "first second                    \n",
      "L1_A  L2_1   -0.248803 -0.646653\n",
      "      L2_2   -1.469062 -0.066386\n",
      "L1_B  L2_1    1.052802  0.237280\n",
      "      L2_2    0.175311 -0.936208\n",
      "L1_C  L2_1   -1.681947 -0.610479\n",
      "      L2_2   -0.021120  0.936238\n",
      "L1_D  L2_1    1.795785  0.703426\n",
      "      L2_2   -1.351722  1.509233\n",
      "first  second   \n",
      "L1_A   L2_1    A   -0.248803\n",
      "               B   -0.646653\n",
      "       L2_2    A   -1.469062\n",
      "               B   -0.066386\n",
      "L1_B   L2_1    A    1.052802\n",
      "               B    0.237280\n",
      "       L2_2    A    0.175311\n",
      "               B   -0.936208\n",
      "L1_C   L2_1    A   -1.681947\n",
      "               B   -0.610479\n",
      "       L2_2    A   -0.021120\n",
      "               B    0.936238\n",
      "L1_D   L2_1    A    1.795785\n",
      "               B    0.703426\n",
      "       L2_2    A   -1.351722\n",
      "               B    1.509233\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "tuples = list(zip(*[['L1_A', 'L1_A', 'L1_B', 'L1_B','L1_C', 'L1_C', 'L1_D', 'L1_D'], ['L2_1', 'L2_2', 'L2_1','L2_2','L2_1', 'L2_2', 'L2_1','L2_2']]))\n",
    "index = pd.MultiIndex.from_tuples(tuples, names=['first', 'second'])\n",
    "data = pd.DataFrame(np.random.randn(8, 2), index=index, columns=['A', 'B'])\n",
    "print data\n",
    "result=data.stack()\n",
    "print result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">A</th>\n",
       "      <th colspan=\"2\" halign=\"left\">B</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second</th>\n",
       "      <th>L2_1</th>\n",
       "      <th>L2_2</th>\n",
       "      <th>L2_1</th>\n",
       "      <th>L2_2</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L1_A</th>\n",
       "      <td>-0.248803</td>\n",
       "      <td>-1.469062</td>\n",
       "      <td>-0.646653</td>\n",
       "      <td>-0.066386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_B</th>\n",
       "      <td>1.052802</td>\n",
       "      <td>0.175311</td>\n",
       "      <td>0.237280</td>\n",
       "      <td>-0.936208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_C</th>\n",
       "      <td>-1.681947</td>\n",
       "      <td>-0.021120</td>\n",
       "      <td>-0.610479</td>\n",
       "      <td>0.936238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1_D</th>\n",
       "      <td>1.795785</td>\n",
       "      <td>-1.351722</td>\n",
       "      <td>0.703426</td>\n",
       "      <td>1.509233</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A                   B          \n",
       "second      L2_1      L2_2      L2_1      L2_2\n",
       "first                                         \n",
       "L1_A   -0.248803 -1.469062 -0.646653 -0.066386\n",
       "L1_B    1.052802  0.175311  0.237280 -0.936208\n",
       "L1_C   -1.681947 -0.021120 -0.610479  0.936238\n",
       "L1_D    1.795785 -1.351722  0.703426  1.509233"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            First_Name Last_Name\n",
      "Customer_ID                     \n",
      "1                   A1        B1\n",
      "2                   A2        B2\n",
      "3                   A3        B3\n",
      "4                   A4        B4\n",
      "  Customer_ID Product_ID product\n",
      "0           1        100     Oil\n",
      "1           1        200   Sugar\n",
      "2           1        300     Tea\n",
      "3           4        400    Milk\n",
      "4           5        500    Eggs\n"
     ]
    }
   ],
   "source": [
    "joined= customers.join(shopping_history, how= 'outer', on=\")\n",
    "print shopping_history\n",
    "print customers\n",
    "print joined"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise:** Try to implement the same code using pivot (http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.pivot.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplication: \n",
    "\n",
    "The DataFrame method 'duplicated' returns a Boolean Series indicating whether each row is a duplicate or not:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "first  second\n",
       "L1_A   L2_A      False\n",
       "       L2_A      False\n",
       "L1_B   L2_B      False\n",
       "       L2_B      False\n",
       "L1_C   L2_C      False\n",
       "       L2_C      False\n",
       "L1_D   L2_D      False\n",
       "       L2_D      False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relatedly, 'drop_duplicates' returns a DataFrame where the duplicated array is without duplicated rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k1  k2\n",
      "0    Milk   1\n",
      "1    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "4  Cheese   3\n",
      "5  Cheese   4\n",
      "6  Cheese   4\n",
      "       k1  k2\n",
      "0    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "5  Cheese   4\n"
     ]
    }
   ],
   "source": [
    "data = pd.DataFrame({'k1': ['Milk'] * 3 + ['Cheese'] * 4,  'k2': [1, 1, 2, 3, 3, 4, 4]})\n",
    "print data\n",
    "data.duplicated()\n",
    "cleandata= data.drop_duplicates()\n",
    "print cleandata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have noticed, applying drop_duplicates on the whole DataFrame considrs all othe columns together. We can alternatively specify which column we want to capture the duplication at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       k1  k2\n",
      "0    Milk   1\n",
      "3  Cheese   3\n",
      "       k1  k2\n",
      "0    Milk   1\n",
      "2    Milk   2\n",
      "3  Cheese   3\n",
      "5  Cheese   4\n"
     ]
    }
   ],
   "source": [
    "v1= data.drop_duplicates(['k1'])\n",
    "print v1\n",
    "v2=  data.drop_duplicates(['k2'])\n",
    "print v2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Renaming axis indecies: \n",
    "\n",
    "Pandas enable modifying the current attribute name using map or renaming methods. Example is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          day1  day2  day3  day4\n",
      "nsw          0     1     2     3\n",
      "vic          4     5     6     7\n",
      "tasmania     8     9    10    11\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY1</th>\n",
       "      <th>DAY2</th>\n",
       "      <th>DAY3</th>\n",
       "      <th>DAY4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NSW</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIC</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASMANIA</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DAY1  DAY2  DAY3  DAY4\n",
       "NSW          0     1     2     3\n",
       "VIC          4     5     6     7\n",
       "TASMANIA     8     9    10    11"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf= pd.DataFrame(np.arange(12).reshape((3, 4)), \n",
    "                  index=['nsw', 'vic', 'tasmania'],\n",
    "                  columns=['day1', 'day2', 'day3', 'day4'])\n",
    "print idf\n",
    "idf.index.map(str.upper)\n",
    "idf.rename(index=str.upper, columns=str.upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>nsw</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vic</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tasmania</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          day1  day2  day3  day4\n",
       "nsw          0     1     2     3\n",
       "vic          4     5     6     7\n",
       "tasmania     8     9    10    11"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note rename keeps the original value of the data unchanged. To change the original DataFrame, you need to do that in place. You can also  rename a subset of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY1</th>\n",
       "      <th>DAY2</th>\n",
       "      <th>DAY3</th>\n",
       "      <th>DAY4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NSW</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VIC</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TASMANIA</th>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DAY1  DAY2  DAY3  DAY4\n",
       "NSW          0     1     2     3\n",
       "VIC          4     5     6     7\n",
       "TASMANIA     8     9    10    11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#idf.index=idf.index.map(str.upper)\n",
    "#OR\n",
    "idf.rename(index=str.upper, columns=str.upper, inplace=True)\n",
    "idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grouping and filtering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k1  k2\n",
       "0    Milk   1\n",
       "2    Milk   2\n",
       "3  Cheese   3\n",
       "5  Cheese   4"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd1 = cleandata.groupby('k1') # group by 'k1' and save \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.groupby.DataFrameGroupBy"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cd1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cheese': [3, 5], 'Milk': [0, 2]}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd1.groups # two groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cheese    2\n",
       "Milk      2\n",
       "Name: k1, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# similar to: \n",
    "cleandata['k1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Milk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k1  k2\n",
       "0    Milk   1\n",
       "2    Milk   2\n",
       "3  Cheese   3\n",
       "5  Cheese   4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter, the groupby was on 'k1' so 'x' means 'k1'\n",
    "cd1.filter(lambda x: len(x) > 1) # groups bigger than 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [k1, k2]\n",
       "Index: []"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd1.filter(lambda x: len(x) > 2) # groups bigger than 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# group on 'k2' - these are unique so not much point\n",
    "cd2 = cleandata.groupby('k2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: [0], 2: [2], 3: [3], 4: [5]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd2.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    1\n",
       "3    1\n",
       "2    1\n",
       "1    1\n",
       "Name: k2, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleandata['k2'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>k2</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    k1\n",
       "k2    \n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd2.count() # there's one of each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add a row\n",
    "cd = cleandata.append({'k1':'Bread','k2':5}, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Milk</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Milk</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cheese</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bread</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       k1  k2\n",
       "0    Milk   1\n",
       "1    Milk   2\n",
       "2  Cheese   3\n",
       "3  Cheese   4\n",
       "4   Bread   5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cd3 = cd.groupby('k1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k1</th>\n",
       "      <th>k2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bread</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      k1  k2\n",
       "4  Bread   5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd3.filter(lambda x: len(x) < 2) # groups less than 2, i.e 1 ('cos there ain't any 0s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Bread': [4], 'Cheese': [2, 3], 'Milk': [0, 1]}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cd3.groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More details and examples can be found in http://pandas.pydata.org/pandas-docs/stable/merging.html and \"Python for Data Analysis\" book pages 177-193.\n",
    "https://nikolaygrozev.wordpress.com/2015/07/01/reshaping-in-pandas-pivot-pivot-table-stack-and-unstack-explained-with-pictures/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "name": "Chapter 6_Merging and Reshaping Data.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
