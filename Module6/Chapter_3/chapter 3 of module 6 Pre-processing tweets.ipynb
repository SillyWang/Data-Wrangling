{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Pre-processing tweets\n",
    "\n",
    "Twitter is a popular micro blogging service where Twitter users communicate with short, 140-character status messages (called \"tweets\"), with which users can share links, pictures, and thoughts or opinions about different topics, journalists comment on live events, companies promote products and engage with customers and so on.\n",
    "With about a half a billion tweets per day, there’s a lot of data to analyse and to play with.\n",
    "Twitter data has been used in various analysis tasks, such as sentiment analysis, social network analysis, etc.\n",
    "Topics that you will learn about in this chapter include:\n",
    "* Collecting tweets via API requests, and storing them in JSON files\n",
    "* Extracting emoticons\n",
    "* Tokenizing tweets \n",
    "* Generating word feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Collecting Tweets with Python \n",
    "Many web services provide APIs to developers to interact with their services and to access data in a programmatic way.\n",
    "Twitter is one of them.\n",
    "It has taken great care to maintain a well-documented and elegantly simple API that is intuitive and easy to use. \n",
    "There are two types of APIs, i.e., [the Streaming API](https://dev.twitter.com/streaming/overview) and [the REST API](https://dev.twitter.com/rest/public/search), available for Twitter developers.\n",
    "According to the documentation on the Twitter developers' website,\n",
    "the former only sends out real-time tweets. \n",
    "It gives developers low latency access to Twitter’s global stream of Tweet data.\n",
    "The later searches against a sample of recent Tweets published in the past 7 days. \n",
    "It is more suitable for singular searches, such as searching historic tweets, reading user profile information, or posting Tweets.\n",
    "While the Streaming API is focused on matching for completeness, the REST API, like the Twitter search API, is focused on relevance. \n",
    "In this section, you will learn the basic usage of the Twitter search API.\n",
    "\n",
    "\n",
    "There are [many great libraries available]((https://dev.twitter.com/overview/api/twitter-libraries) in different programming languages to further ease the work involved in making API requests. \n",
    "Using those libraries, you can easily make API requests without having to know too much\n",
    "about the Twitter API details.\n",
    "Here we will use [TwitterSearch](https://github.com/ckoepp/TwitterSearch), \n",
    "a Python library to easily iterate tweets found by the [Twitter search API](https://dev.twitter.com/rest/public/search),\n",
    "to demonstrate how to make Twitter API requests and download data of our interest, \n",
    "we chose the TwitterSearch library, because it is simple to use, yet supports the Twitter search API well.\n",
    "If you don't have TwitterSearch installed in your machine, go to its Github website and follow\n",
    "the installation instructions.\n",
    "\n",
    "To start with, you need to have a Twitter account and obtain credentials (i.e., consumer key, consumer secret, access token and access token secret) on the Twitter developer site to access the Twitter API.\n",
    "Follow the steps below to get all the 4 credentials:\n",
    "* Create a Twitter user account if you do not already have one.\n",
    "* Go to https://apps.twitter.com/ and log in with your Twitter user account. This step gives you a Twitter developer account under the same name as your user account.\n",
    "* Click “Create New App”, and then fill out the form (i.e., App name, App description, and so on), agree to the terms, and click “Create your Twitter application”.\n",
    "Creating an application is the standard way for a developer to gain API access.\n",
    "The process of creating an application is simple, and all that's needed is read-only access to the API.\n",
    "* In the next page, click on “Keys and Access Tokens” tab on the top, \n",
    "    and copy your “consumer key” and “consumer secret”. \n",
    "* Scroll down if necessary and click “Create my access token”, and copy your “Access token” and “Access token secret”.\n",
    " \n",
    "Below is example code to search Twitter for tweets that have keyword 'metrotrains',\n",
    "and save all the retrieved tweets in list.\n",
    "In order to run the code, you should substituting your own account credentials that you just got above in order to creat the TwitterSearch object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from TwitterSearch import *\n",
    "\n",
    "tweets = []\n",
    "\n",
    "try:\n",
    "    # create a TwitterSearchOrder object\n",
    "    tso = TwitterSearchOrder() \n",
    "    # let's define all words we would like to have a look for\n",
    "    tso.set_keywords(['metrotrains']) \n",
    "    # or is English the default\n",
    "    tso.set_language('en') \n",
    "    # and give us all those entity information\n",
    "    tso.set_include_entities(False) \n",
    "\n",
    "    # create a TwitterSearch object with your own credentials\n",
    "    ts = TwitterSearch(\n",
    "        consumer_key = 'eN520aLznqki9cP2A0sKs1ASo',\n",
    "        consumer_secret = 'tJXOWAqqt6X9VLdnXIdE566YaxWC3kO3jIUCU3WFbMpdFDlb5E',\n",
    "        access_token = '110647198-iugV15WVDTOObIaQPB1G6rj4oqiHwpjXTKaasMv8',\n",
    "        access_token_secret = 'sVWFxfxXI3SUG9DDzp516wRhKxjSYjOIpw7iXF7OzDxRZ'\n",
    "     )\n",
    "\n",
    "    for tweet in ts.search_tweets_iterable(tso):\n",
    "        tweets.append(tweet) \n",
    "        \n",
    "# take care of all those ugly errors if there are some        \n",
    "except TwitterSearchException as e: \n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run the program above, you will retrieve about 2,300 tweets that contain 'metrotrains'. \n",
    "Note that the number of tweets retrieved might vary from time to time, \n",
    "as the whole Twitter database is dynamic due to thousands of tweets being posted every second.\n",
    "Each tweet is stored in a huge Python dictionary.\n",
    "An example of what such a tweet looks like is the following dictionary, which\n",
    "corresponds to the first tweet returned by the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Wed Oct 05 08:18:00 +0000 2016',\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'geo': None,\n",
       " 'id': 783581993422450688,\n",
       " 'id_str': '783581993422450688',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'en',\n",
       " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       " 'place': None,\n",
       " 'retweet_count': 3,\n",
       " 'retweeted': False,\n",
       " 'retweeted_status': {'contributors': None,\n",
       "  'coordinates': None,\n",
       "  'created_at': 'Wed Oct 05 07:55:13 +0000 2016',\n",
       "  'favorite_count': 2,\n",
       "  'favorited': False,\n",
       "  'geo': None,\n",
       "  'id': 783576262111485952,\n",
       "  'id_str': '783576262111485952',\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'is_quote_status': False,\n",
       "  'lang': 'en',\n",
       "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
       "  'place': None,\n",
       "  'possibly_sensitive': False,\n",
       "  'retweet_count': 3,\n",
       "  'retweeted': False,\n",
       "  'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       "  'text': \"I'm over replacement buses, so I would like to see if people can make funny captions/puns for this pic @metrotrains https://t.co/WUazDWPf28\",\n",
       "  'truncated': False,\n",
       "  'user': {'contributors_enabled': False,\n",
       "   'created_at': 'Mon Mar 30 04:08:29 +0000 2009',\n",
       "   'default_profile': False,\n",
       "   'default_profile_image': False,\n",
       "   'description': 'Train Enthusiast, User of Public Transport, Fashion, Youtube, Science, Shoes, Weather, Video Games and Current world affairs. Like a bag of all sorts!',\n",
       "   'entities': {'description': {'urls': []}},\n",
       "   'favourites_count': 2391,\n",
       "   'follow_request_sent': False,\n",
       "   'followers_count': 778,\n",
       "   'following': False,\n",
       "   'friends_count': 1673,\n",
       "   'geo_enabled': False,\n",
       "   'has_extended_profile': True,\n",
       "   'id': 27581047,\n",
       "   'id_str': '27581047',\n",
       "   'is_translation_enabled': False,\n",
       "   'is_translator': False,\n",
       "   'lang': 'en',\n",
       "   'listed_count': 26,\n",
       "   'location': 'Melbourne, Australia',\n",
       "   'name': 'Madison aka Kylie',\n",
       "   'notifications': False,\n",
       "   'profile_background_color': '1F8BFF',\n",
       "   'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/378800000099691672/2547218a9a160116c0b251c9a9c913dd.png',\n",
       "   'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/378800000099691672/2547218a9a160116c0b251c9a9c913dd.png',\n",
       "   'profile_background_tile': True,\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/27581047/1474711806',\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/783197456615911424/qp5-iPKW_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/783197456615911424/qp5-iPKW_normal.jpg',\n",
       "   'profile_link_color': 'AF5EFF',\n",
       "   'profile_sidebar_border_color': '000000',\n",
       "   'profile_sidebar_fill_color': 'FFA6C9',\n",
       "   'profile_text_color': 'FF089D',\n",
       "   'profile_use_background_image': True,\n",
       "   'protected': False,\n",
       "   'screen_name': 'boomerangmadi',\n",
       "   'statuses_count': 6564,\n",
       "   'time_zone': 'Melbourne',\n",
       "   'url': None,\n",
       "   'utc_offset': 39600,\n",
       "   'verified': False}},\n",
       " 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
       " 'text': \"RT @boomerangmadi: I'm over replacement buses, so I would like to see if people can make funny captions/puns for this pic @metrotrains http…\",\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Fri Jan 31 09:30:32 +0000 2014',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'description': '17 Y/O, looking forward to a sustainable future for #Bentleigh and Victoria. Big fan of #springst ,Public Transport/Railways, urban planning, and @Everton.',\n",
       "  'entities': {'description': {'urls': []}},\n",
       "  'favourites_count': 8768,\n",
       "  'follow_request_sent': False,\n",
       "  'followers_count': 1343,\n",
       "  'following': False,\n",
       "  'friends_count': 1775,\n",
       "  'geo_enabled': True,\n",
       "  'has_extended_profile': True,\n",
       "  'id': 2320525034,\n",
       "  'id_str': '2320525034',\n",
       "  'is_translation_enabled': False,\n",
       "  'is_translator': False,\n",
       "  'lang': 'en',\n",
       "  'listed_count': 53,\n",
       "  'location': 'these views are my own.',\n",
       "  'name': 'Declan Martin',\n",
       "  'notifications': False,\n",
       "  'profile_background_color': 'FA743E',\n",
       "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme17/bg.gif',\n",
       "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme17/bg.gif',\n",
       "  'profile_background_tile': False,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2320525034/1466411474',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/711469911441190913/vlrcF2dM_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/711469911441190913/vlrcF2dM_normal.jpg',\n",
       "  'profile_link_color': '9266CC',\n",
       "  'profile_sidebar_border_color': 'DBE9ED',\n",
       "  'profile_sidebar_fill_color': 'E6F6F9',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'declanmartin75',\n",
       "  'statuses_count': 16953,\n",
       "  'time_zone': 'Melbourne',\n",
       "  'url': None,\n",
       "  'utc_offset': 39600,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0]\n",
    "# try the following print out, what do you find?\n",
    "# print tweets[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above example, you can see that the Twitter search API returns not only the content of tweets but also rich meta information, e.g., user information, when the tweet posted, the number of retweets and so on.\n",
    "All the data is stored in JSON format.\n",
    "It is clear that each tweet object contains far more data than the 140 characters of text that is normally thought of as a tweet! \n",
    "Click [here](http://www.slaw.ca/wp-content/uploads/2011/11/map-of-a-tweet-copy.pdf) to view the map made by Raffi Krikorian, which explains a tweet in JSON format.\n",
    "This map is a good visualization of tweet’s JSON format even though it is a bit out-of-date. \n",
    "You can find the up-to-date information of tweet’s format [here](https://dev.twitter.com/overview/api/tweets).\n",
    "We will discuss the tweet structure in a bit more detail later.\n",
    "The following code uses Python library *json* or *simplejson* to dump all the tweets into a JSON file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary package to process data in JSON format\n",
    "try:\n",
    "    import json\n",
    "except ImportError:\n",
    "    import simplejson as json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# dump all the tweets into a JSON file\n",
    "jsonFile = open('tweetSamples_1.json', 'w')\n",
    "for tweet in tweets:\n",
    "    # Twitter Python Tool wraps the data returned by Twitter as a Dictionary object.\n",
    "    # We first convert it back to the JSON format, and then save all tweets in a JSON file\n",
    "    jsonFile.write(json.dumps(tweet)+\"\\n\")\n",
    "jsonFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Note that Twitter imposes rate limits on how many requests an application can make to any given API resource within a given time window. \n",
    "Twitter's rate limits are well documented (see [here](https://dev.twitter.com/rest/public/rate-limits)).\n",
    "For the purpose of following along in this chapter, it is unlikely that you will hit the rate limits.\n",
    "We have introduced the use of the Twitter search API. As we mentioned early in this section, there are other APIs\n",
    "that you can use, the Twitter stream API for example. \n",
    "If you would like to learn more on Twitter APIs, you can go to \n",
    "[Twitter's website for developers](https://dev.twitter.com/overview/documentation), \n",
    "or read some online tutorials such as [3].\n",
    "- - -\n",
    "\n",
    "## 2. Reading and Processing Tweets in JSON formats\n",
    "Here we demonstrate how to read and process tweets in a bit more detail.\n",
    "We will use `json` library to parse the dumped tweets (please refer to chapter 2 of Module 2 on the detailed discussion of JSON), and then show how to pre-process the text content, which includes handling emoticons, tokenizing tweets, and generating feature words.\n",
    "\n",
    "### 2.1. Loading Tweets from a Dump File\n",
    "Let's first load the tweets from a dump file,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import codecs\n",
    "tweets = []\n",
    "f = codecs.open(\"tweetSamples.json\", \"r\", \"utf-8\")\n",
    "for line in f:\n",
    "    tweet = json.loads(line)\n",
    "    tweets.append(tweet) \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the previous section, we have seen that each tweet object contains not only the text content but also \n",
    "other related information. \n",
    "Let's have a look at the structure of a tweet.\n",
    "Recall that each tweet is stored in a Python dictionary.\n",
    "Thus, to view all the attributes (or fields), simply type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text', 'retweet_count', 'source', 'in_reply_to_user_id', 'coordinates', 'place', 'in_reply_to_status_id_str', 'contributors', 'id_str', 'in_reply_to_user_id_str', 'id', 'in_reply_to_status_id', 'created_at', 'geo', 'metadata', 'is_quote_status', 'favorited', 'lang', 'retweeted', 'truncated', 'user', 'in_reply_to_screen_name', 'favorite_count'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The key fields are the following:\n",
    "* text: the text content of the tweet itself\n",
    "* created_at: when the tweet was posted\n",
    "* favorite_count, retweet_count: the number of favourites and retweets\n",
    "* favorited, retweeted: Boolean stating whether the authenticated user has favourited or retweeted this tweet\n",
    "* lang: the language used for the tweet (e.g. “en” for English)\n",
    "* id: the unique tweet identifier\n",
    "* id_str: The string representation of the tweet identifier\n",
    "* place, coordinates, geo: geo-location information if available\n",
    "* user: the full profile of the user, which contains user's id, name,  screen_name and so on.\n",
    "* entities: list of entities like URLs, @-mentions, hashtags and symbols\n",
    "\n",
    "As you can see there’s a lot of information we can use in analysing tweets.\n",
    "You can imagine how the data stored in those fields already allows for some interesting analysis,\n",
    "for example, you can check who is most favourited/retweeted, what are the most popular hashtags, etc. \n",
    "Assume we are going to extract data stored in the following fields\n",
    "* id\n",
    "* created_at\n",
    "* text\n",
    "* user's id\n",
    "* user's name\n",
    "* user's screen_name\n",
    "\n",
    "and store them in a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tweets_pddf = pd.DataFrame()\n",
    "tweets_pddf['id'] = list(map(lambda tweet: tweet['id'], tweets))\n",
    "tweets_pddf['user_id'] = list(map(lambda tweet: tweet['user']['id'], tweets))\n",
    "tweets_pddf['user_name'] = list(map(lambda tweet: tweet['user']['name'], tweets))\n",
    "tweets_pddf['user_sname'] = list(map(lambda tweet: tweet['user']['screen_name'], tweets))\n",
    "tweets_pddf['created_at'] = list(map(lambda tweet: tweet['created_at'], tweets))\n",
    "tweets_pddf['text'] = list(map(lambda tweet: tweet['text'], tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_sname</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710240637497380864</td>\n",
       "      <td>534729059</td>\n",
       "      <td>Luke Sabatini</td>\n",
       "      <td>luke_sabatini</td>\n",
       "      <td>Wed Mar 16 23:05:38 +0000 2016</td>\n",
       "      <td>.@metrotrains, another day another diverted la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>710240382311731200</td>\n",
       "      <td>215322466</td>\n",
       "      <td>Sina Marandian</td>\n",
       "      <td>myCroon</td>\n",
       "      <td>Wed Mar 16 23:04:37 +0000 2016</td>\n",
       "      <td>@metrotrains 12 mins delay YET AGAIN on Flinde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>710239778554257408</td>\n",
       "      <td>947522706</td>\n",
       "      <td>Brett Keleher</td>\n",
       "      <td>thebrickcleaner</td>\n",
       "      <td>Wed Mar 16 23:02:13 +0000 2016</td>\n",
       "      <td>@danielbowen @VLine @jimbob_prod @metrotrains ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>710238746688364545</td>\n",
       "      <td>215322466</td>\n",
       "      <td>Sina Marandian</td>\n",
       "      <td>myCroon</td>\n",
       "      <td>Wed Mar 16 22:58:07 +0000 2016</td>\n",
       "      <td>@metrotrains not sure if guys who run Melbourn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710238698428706816</td>\n",
       "      <td>94544311</td>\n",
       "      <td>Ant</td>\n",
       "      <td>AntB77</td>\n",
       "      <td>Wed Mar 16 22:57:55 +0000 2016</td>\n",
       "      <td>@metrotrains and we're away 10 min late</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id    user_id       user_name       user_sname  \\\n",
       "0  710240637497380864  534729059   Luke Sabatini    luke_sabatini   \n",
       "1  710240382311731200  215322466  Sina Marandian          myCroon   \n",
       "2  710239778554257408  947522706   Brett Keleher  thebrickcleaner   \n",
       "3  710238746688364545  215322466  Sina Marandian          myCroon   \n",
       "4  710238698428706816   94544311             Ant           AntB77   \n",
       "\n",
       "                       created_at  \\\n",
       "0  Wed Mar 16 23:05:38 +0000 2016   \n",
       "1  Wed Mar 16 23:04:37 +0000 2016   \n",
       "2  Wed Mar 16 23:02:13 +0000 2016   \n",
       "3  Wed Mar 16 22:58:07 +0000 2016   \n",
       "4  Wed Mar 16 22:57:55 +0000 2016   \n",
       "\n",
       "                                                text  \n",
       "0  .@metrotrains, another day another diverted la...  \n",
       "1  @metrotrains 12 mins delay YET AGAIN on Flinde...  \n",
       "2  @danielbowen @VLine @jimbob_prod @metrotrains ...  \n",
       "3  @metrotrains not sure if guys who run Melbourn...  \n",
       "4            @metrotrains and we're away 10 min late  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_pddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the material we’re looking for, i.e. the content of a tweet, is embedded in the text, and that’s where we’re starting our analysis.\n",
    "Twitter only allows 140 characters of textual content for each tweet, which can roughly correspond to thoughts or ideas of Twitter users.\n",
    "The 140 characters may include one or more entities and reference one or more places that map to locations in the real world. \n",
    "To make it a bit more concrete, let's have a look at the textual content of the first tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".@metrotrains, another day another diverted late city loop train from Caulfield straight to Flinders! @9NewsMelb! #cheers\n"
     ]
    }
   ],
   "source": [
    "print(tweets_pddf['text'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tweet is 121 characters long and contains three tweet entities: the user mentions '@metrotrains' and '@9NewsMelb', and the hashtag '#cheers'. Besides user mentions and hashtags, most tweets also contain emoticons, for instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less than 10kms from the city and it has taken @metrotrains an hour and 20 minutes to get me there. Hats off all 🎩👏🏻 keep up the good work\n"
     ]
    }
   ],
   "source": [
    "print(tweets_pddf['text'][2162])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike formally written English, e.g., newswire-like text, \n",
    "tweets do often not confirm to rules of spelling, grammar, and punctuation.\n",
    "They often contain acronyms, typos, emoticons and other characters that express special meanings. \n",
    "Therefore, pre-processing tweets needs special treatment, compared with pre-processing formally written English text.\n",
    "In the rest of this section, you will learn how to manipulate tweets into a form that can be digested by text analysis algorithms used in tasks, such as sentiment analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Looking for Emoticons \n",
    "[Emoticons](https://en.wikipedia.org/wiki/Emoticon), such as 😂,😊,😡,😀, etc. are frequently used tweets and other kinds of online social iterations. They are designed to add emotional flavor to plain text messages, especially in short messages like tweets.\n",
    "Because they are often direct signals of sentiment, emoticons in text have been widely used as features in \n",
    "sentiment analysis or as entries of sentiment lexicons.\n",
    "Given a large amount of tweets posted every day, it would be interesting for businesses and researchers \n",
    "to understand the prevalence of emoticons on Twitter, how users express and perceive sentiment\n",
    "through emoticons, and whether emoticons can be used as a reliable cue for identifying sentiment polarity.\n",
    "In many of the existing sentiment analysis algorithms, emoticons played an important\n",
    "role in both building sentiment lexicons and in training classifiers.\n",
    "Discussing sentiment analysis iteself however goes beyond our scope.\n",
    "Instead we will focus on identifying emoticons while pre-processing tweets.\n",
    "\n",
    "Let's start with looking for a tweet that contains \"Hats off all 🎩👏🏻\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_text = map(lambda tweet: tweet['text'], tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less than 10kms from the city and it has taken @metrotrains an hour and 20 minutes to get me there. Hats off all 🎩👏🏻 keep up the good work\n"
     ]
    }
   ],
   "source": [
    "t =''\n",
    "for text in tweets_text:\n",
    "    if \"Hats off all\" in text:\n",
    "        t = text\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the emotcons really look like? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Less than 10kms from the city and it has taken @metrotrains an hour and 20 minutes to get me there. Hats off all 🎩👏🏻 keep up the good work'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Emoticons are conventionally represented by punctuation marks, numbers and letters, such as :-), :D, :(, etc.\n",
    "See Wikipedia entry on \"[List of emoticons](https://en.wikipedia.org/wiki/List_of_emoticons)\".\n",
    "They have been introduced in Unicode since 2010.\n",
    "As you can see above, all the emoticons are represented by Unicode strings, such as '\\U0001f44f' corresponding to 👏.\n",
    "[The standard emoticons](http://www.unicode.org/charts/PDF/U1F600.pdf ) covers Unicode range from 1F600 to 1F64F,\n",
    "i.e., \\u0001F600 to \\u0001F64F. For example,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "😀\n",
      "😁\n",
      "😊\n",
      "🙀\n",
      "🙏\n"
     ]
    }
   ],
   "source": [
    "print(u'\\U0001f600')\n",
    "print(u'\\U0001f601')\n",
    "print(u'\\U0001f60A')\n",
    "print(u'\\U0001f640')\n",
    "print(u'\\U0001f64f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of emoticons that can be used by Twitter users can be found [here](http://www.secret-emoticons.com/twitter-emoticons). It contains far more rich emoticons than the standard set. \n",
    "We have known how emoticons are represented in tweets.\n",
    "Next, we are going to extract emoticons and save it in one column in our DataFrame `tweets_pddf`.\n",
    "\n",
    "If you google \"find emoticons python\", you will probably find the stackoverflow's webpage on \"[How to find and count emoticons in a string using python?](http://stackoverflow.com/questions/19149186/how-to-find-and-count-emoticons-in-a-string-using-python)\".\n",
    "This webpage has shown a couple of ways of finding standard emoticons. \n",
    "Let's try the first answer, which is\n",
    "```python\n",
    "    import re\n",
    "    s=u\"Smiley emoticon rocks!\\U0001f600 I like you.\\U0001f601\"\n",
    "    count = len(re.findall(ur'[\\U0001f600-\\U0001f650]', s))\n",
    "```\n",
    "where \n",
    "```python\n",
    "    [\\U0001f600-\\U0001f650]\n",
    "```\n",
    "specifies Unicode range used for standard emoticons,\n",
    "and \"u\" makes the regular expression a Unicode-escape string.\n",
    "The regular expression engine is supposed to find all emtoticons in `s`, whose Unicode strings are in the range.\n",
    "Let's adapt the code to the tweet containing \"Hats off all 🎩👏🏻\" to see if it can find 👏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "re.findall('[\\U0001f600-\\U0001f650]', t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the code does not work and returns an error saying \"bad character range\".\n",
    "This is because the Python version before 3.3 allows only \"narrow Unicode\" builds, where\n",
    "characters can only be in the range U+0000 to U+FFFF, whereas Python version after 3.3\n",
    "allows \"wide Unicode\" builds, where Unicode can go beyond U+FFFF.\n",
    "It looks like that there is no way to search for the emoticons using Python version before 3.3.\n",
    "Fortunately, we found `emoji`, a Python library that supports the entire set of Emoji codes as\n",
    "defined by [the Unicode consortium](http://www.unicode.org/emoji/charts/full-emoji-list.html).\n",
    "This library can run with Python 2.7.\n",
    "To install this package, type the following `pip` into your command window:\n",
    "```\n",
    "    pip install emoji --upgrade\n",
    "```\n",
    "Try to print some emoticons from its [Cheat Sheet](http://www.emoji-cheat-sheet.com/):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simle 😄\n",
      "heart_eyes 😍\n",
      "smiling_imp 😈\n",
      "book 📖\n"
     ]
    }
   ],
   "source": [
    "import emoji \n",
    "\n",
    "print(emoji.emojize('simle :smile:', use_aliases=True))\n",
    "print(emoji.emojize('heart_eyes :heart_eyes:', use_aliases=True))\n",
    "print(emoji.emojize('smiling_imp :smiling_imp:', use_aliases=True))\n",
    "print(emoji.emojize('book :book:', use_aliases=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To extract all the emoticons in a tweet, we are going to use the `emoji.get_emoji_regexp()` method\n",
    "that returns a compiled regular expression that matches all the emoticons defined in `emoji`,\n",
    "and then pass this regular expression to the `findall` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎩 : '🎩'\n",
      "👏 : '👏'\n",
      "🏻 : '🏻'\n"
     ]
    }
   ],
   "source": [
    "emoticon_regexp = emoji.get_emoji_regexp() # get the regular expressions for all emoticons\n",
    "ems = re.findall(emoticon_regexp, t) # find all emoticons\n",
    "for e in ems:\n",
    "    print(e, \":\", repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now wrap the first two lines of the code above in a Python function, and make it a callable function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def findEmoticons(text):\n",
    "    emoticon_regexp = emoji.get_emoji_regexp()\n",
    "    emoticons = re.findall(emoticon_regexp, text) \n",
    "    return emoticons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This function can be applied to each tweet and check if it contains any emoticons.\n",
    "Let's find all tweets that contain one or more emoticons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#tweets containing emoticon:  0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for tweet in tweets_text:\n",
    "    emoticons = findEmoticons(tweet)\n",
    "    if len(emoticons) > 0:\n",
    "        print(tweet)\n",
    "        #print ', '.join(emoticons)\n",
    "        count = count + 1\n",
    "print(\"\\n#tweets containing emoticon: \", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The total number of tweets containing at least one emoticon defined in `emoji` is 67. \n",
    "Given the total number of tweets that we have, it seems that there are not many tweets containing emoticons.\n",
    "We might also need to consider the emoticons that are represented by punctuation marks, numbers and letters, such as :-), :D, :(, etc. We will leave it as an exercise for you to extract all those conventional emoticons.\n",
    "\n",
    "Counting observable things is the start point for any kind of statistical analysis or manipulation that strives to find what may be a faint signal in raw data [1]. Whereas we just extracted all the emoticons in all the tweets loaded from the dump file, let's now take a closer look at the frequency distribution of those emoticons and print out the most frequent emoticons. \n",
    "\n",
    "In the previous chapter, you have learnt how to use the `FreqDist` class in NLTK. \n",
    "Here we are going to use the `collections` module in Python, which provides a `Counter` class that\n",
    "can compute a frequency distribution of a given data. \n",
    "Indeed, the `FreqDist` class is implemented with the `Counter` class.\n",
    "The code below demonstrates how to use a `Counter` object to compute frequency distribution as a ranked list of emoticons. Counting frequency distributions is the simplest technique used in analysing Twitter data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import collections\n",
    "em_list = []\n",
    "for tweet in tweets_text:\n",
    "     em_list += findEmoticons(tweet)\n",
    "em_counter = collections.Counter(em_list)\n",
    "em_counter.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, the frequency distribution is represented by a list of key/value pairs corresponding to emoticons in Unicode and their frequencies. \n",
    "Following [1], let's make reviewing the distribution a litte easier for eyeballing by tabulating those key/value pairs.\n",
    "To emit a tabular or table format, you can install a Python package, called [`prettytable`](https://pypi.python.org/pypi/PrettyTable) by typing\n",
    "```\n",
    "    pip install prettytable\n",
    "```\n",
    "in your command window. \n",
    "It is a simple Python library designed to make it quick and easy to represent tabular data in visually appealing ASCII tables. \n",
    "The following code shows how to display the same result in a nicely formatted text-based table that \n",
    "is easy to skim by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+\n",
      "| Emoticons | Count |\n",
      "+-----------+-------+\n",
      "+-----------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "pt = PrettyTable(field_names=['Emoticons','Count'])\n",
    "[pt.add_row(kv) for kv in em_counter.most_common()[:10]]\n",
    "pt.align['Emoticon'], pt.align['Count'] = 'l', 'r'\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick skim of the result could reveal that the most frequent emoticon is 😡, an angry face. \n",
    "Among those tweets containing at least one emoticon, there are more than 25 of them that have negative sentiment on metrotrains, where we assume 💩 indicates negative sentiment.\n",
    "It is quite common in sentiment analysis to use emoticons as clues in determining the sentiment polarity of tweets. \n",
    "However, some research work [4] on the relationship between emoticons and sentiment polarity shows that \n",
    "a few emoticons are strong and reliable signals of sentiment polarity and a large group of the emoticons\n",
    "coveys complicated sentiment where they should be treated carefully, \n",
    "see Figure 1 of [4], a survey of emotion expressed by emoticons.\n",
    "\n",
    "Our last step is to save those emoticons in one column in the DataFrame, `tweets_pddf`, so that the downstream text analyser can directly make use of them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_sname</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>emoticons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710240637497380864</td>\n",
       "      <td>534729059</td>\n",
       "      <td>Luke Sabatini</td>\n",
       "      <td>luke_sabatini</td>\n",
       "      <td>Wed Mar 16 23:05:38 +0000 2016</td>\n",
       "      <td>.@metrotrains, another day another diverted la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>710240382311731200</td>\n",
       "      <td>215322466</td>\n",
       "      <td>Sina Marandian</td>\n",
       "      <td>myCroon</td>\n",
       "      <td>Wed Mar 16 23:04:37 +0000 2016</td>\n",
       "      <td>@metrotrains 12 mins delay YET AGAIN on Flinde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>710239778554257408</td>\n",
       "      <td>947522706</td>\n",
       "      <td>Brett Keleher</td>\n",
       "      <td>thebrickcleaner</td>\n",
       "      <td>Wed Mar 16 23:02:13 +0000 2016</td>\n",
       "      <td>@danielbowen @VLine @jimbob_prod @metrotrains ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>710238746688364545</td>\n",
       "      <td>215322466</td>\n",
       "      <td>Sina Marandian</td>\n",
       "      <td>myCroon</td>\n",
       "      <td>Wed Mar 16 22:58:07 +0000 2016</td>\n",
       "      <td>@metrotrains not sure if guys who run Melbourn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710238698428706816</td>\n",
       "      <td>94544311</td>\n",
       "      <td>Ant</td>\n",
       "      <td>AntB77</td>\n",
       "      <td>Wed Mar 16 22:57:55 +0000 2016</td>\n",
       "      <td>@metrotrains and we're away 10 min late</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>710237588318085120</td>\n",
       "      <td>94544311</td>\n",
       "      <td>Ant</td>\n",
       "      <td>AntB77</td>\n",
       "      <td>Wed Mar 16 22:53:31 +0000 2016</td>\n",
       "      <td>Amateur hr by @metrotrains  Flinders st, 9:49 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>710234915384590336</td>\n",
       "      <td>310818887</td>\n",
       "      <td>Brad Cook</td>\n",
       "      <td>PkmtBrad</td>\n",
       "      <td>Wed Mar 16 22:42:54 +0000 2016</td>\n",
       "      <td>@danielbowen @jimbob_prod @metrotrains @VLine ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>710233767881748480</td>\n",
       "      <td>182766018</td>\n",
       "      <td>Mark Stilve</td>\n",
       "      <td>stilves</td>\n",
       "      <td>Wed Mar 16 22:38:20 +0000 2016</td>\n",
       "      <td>@metrotrains hope our train driver's day gets ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>710232721625206784</td>\n",
       "      <td>387479230</td>\n",
       "      <td>Emily</td>\n",
       "      <td>emtoone</td>\n",
       "      <td>Wed Mar 16 22:34:10 +0000 2016</td>\n",
       "      <td>@metrotrains can you ever have trains running ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>710229717870186496</td>\n",
       "      <td>93570145</td>\n",
       "      <td>Fake Metro Trains</td>\n",
       "      <td>fakemetrotrains</td>\n",
       "      <td>Wed Mar 16 22:22:14 +0000 2016</td>\n",
       "      <td>@esayche Thanks for your feedback! Just do wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>710226759044562944</td>\n",
       "      <td>24331633</td>\n",
       "      <td>esayche</td>\n",
       "      <td>esayche</td>\n",
       "      <td>Wed Mar 16 22:10:29 +0000 2016</td>\n",
       "      <td>.@metrotrains should subsidise this for Lilyda...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>710226086659895297</td>\n",
       "      <td>93570145</td>\n",
       "      <td>Fake Metro Trains</td>\n",
       "      <td>fakemetrotrains</td>\n",
       "      <td>Wed Mar 16 22:07:49 +0000 2016</td>\n",
       "      <td>@littlesandieago Thanks for your feedback! You...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>710225750482223104</td>\n",
       "      <td>2849186803</td>\n",
       "      <td>allyboo</td>\n",
       "      <td>littlesandieago</td>\n",
       "      <td>Wed Mar 16 22:06:28 +0000 2016</td>\n",
       "      <td>@metrotrains Thnx for delivering an express tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>710224901131505664</td>\n",
       "      <td>3254244876</td>\n",
       "      <td>Megh Shetty</td>\n",
       "      <td>Megshetty</td>\n",
       "      <td>Wed Mar 16 22:03:06 +0000 2016</td>\n",
       "      <td>@metrotrains very poor service blgrave line. T...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>710222822719639552</td>\n",
       "      <td>2440721072</td>\n",
       "      <td>Kat Ritchie</td>\n",
       "      <td>kattritchie</td>\n",
       "      <td>Wed Mar 16 21:54:50 +0000 2016</td>\n",
       "      <td>@metrotrains you'd think you'd be able to resp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>710221833757298688</td>\n",
       "      <td>3308204684</td>\n",
       "      <td>PTV HUB</td>\n",
       "      <td>PTVHUB</td>\n",
       "      <td>Wed Mar 16 21:50:55 +0000 2016</td>\n",
       "      <td>RT @metrotrains: Werribee line delays: Please ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>710221762424733696</td>\n",
       "      <td>3308204684</td>\n",
       "      <td>PTV HUB</td>\n",
       "      <td>PTVHUB</td>\n",
       "      <td>Wed Mar 16 21:50:38 +0000 2016</td>\n",
       "      <td>RT @metrotrains: Cranbourne/Pakenham line dela...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>710221042837381121</td>\n",
       "      <td>59771697</td>\n",
       "      <td>Guru Rao</td>\n",
       "      <td>raoguru</td>\n",
       "      <td>Wed Mar 16 21:47:46 +0000 2016</td>\n",
       "      <td>@metrotrains @ptv_official @DanielAndrewsMP th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>710220563029950464</td>\n",
       "      <td>397171390</td>\n",
       "      <td>Rhiannon Rak</td>\n",
       "      <td>rhiannonkatexo</td>\n",
       "      <td>Wed Mar 16 21:45:52 +0000 2016</td>\n",
       "      <td>RT @fakemetrotrains: Good morning Melbourne! I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>710220278547087360</td>\n",
       "      <td>94444054</td>\n",
       "      <td>Bobby Przesmycki</td>\n",
       "      <td>bolekprz</td>\n",
       "      <td>Wed Mar 16 21:44:44 +0000 2016</td>\n",
       "      <td>@metrotrains is without a doubt is the worst P...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>710218790856839168</td>\n",
       "      <td>489088556</td>\n",
       "      <td>Biren Joshi</td>\n",
       "      <td>JoshiBiren</td>\n",
       "      <td>Wed Mar 16 21:38:49 +0000 2016</td>\n",
       "      <td>@ptv_official @metrotrains are worst then conn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>710218105033662464</td>\n",
       "      <td>718022906</td>\n",
       "      <td>Matthew John</td>\n",
       "      <td>thethorpstar</td>\n",
       "      <td>Wed Mar 16 21:36:06 +0000 2016</td>\n",
       "      <td>@metrotrains @CityLinkMelb to cost @DanielAndr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>710217951077486592</td>\n",
       "      <td>1591227588</td>\n",
       "      <td>clear qualia</td>\n",
       "      <td>aspicacity</td>\n",
       "      <td>Wed Mar 16 21:35:29 +0000 2016</td>\n",
       "      <td>RT @fakemetrotrains: Good morning Melbourne! I...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>710217846572261376</td>\n",
       "      <td>138196049</td>\n",
       "      <td>Suburban Tourism</td>\n",
       "      <td>NoHeDaily</td>\n",
       "      <td>Wed Mar 16 21:35:04 +0000 2016</td>\n",
       "      <td>RT @LissanneOliver: Sweet @metrotrains blokes ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>710217581584457728</td>\n",
       "      <td>320078797</td>\n",
       "      <td>Lissanne Oliver</td>\n",
       "      <td>LissanneOliver</td>\n",
       "      <td>Wed Mar 16 21:34:01 +0000 2016</td>\n",
       "      <td>Sweet @metrotrains blokes offering hot drinks ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>710217553524563968</td>\n",
       "      <td>8303822</td>\n",
       "      <td>Daniel Bowen</td>\n",
       "      <td>danielbowen</td>\n",
       "      <td>Wed Mar 16 21:33:54 +0000 2016</td>\n",
       "      <td>@jimbob_prod @metrotrains Seems like odd place...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>710217542292213761</td>\n",
       "      <td>93570145</td>\n",
       "      <td>Fake Metro Trains</td>\n",
       "      <td>fakemetrotrains</td>\n",
       "      <td>Wed Mar 16 21:33:51 +0000 2016</td>\n",
       "      <td>@othiSA Thanks for your feedback! We’re so sca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>710217290562703360</td>\n",
       "      <td>26199526</td>\n",
       "      <td>Dan Nicholas</td>\n",
       "      <td>nnwave</td>\n",
       "      <td>Wed Mar 16 21:32:51 +0000 2016</td>\n",
       "      <td>@metrotrains 3/3 trains for me this week skipp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>710217227857858560</td>\n",
       "      <td>324890519</td>\n",
       "      <td>Amzzz</td>\n",
       "      <td>amzzz13</td>\n",
       "      <td>Wed Mar 16 21:32:36 +0000 2016</td>\n",
       "      <td>Train is going direct to flinders and skipping...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>710216956247298048</td>\n",
       "      <td>489088556</td>\n",
       "      <td>Biren Joshi</td>\n",
       "      <td>JoshiBiren</td>\n",
       "      <td>Wed Mar 16 21:31:32 +0000 2016</td>\n",
       "      <td>@metrotrains previously connex used to get fro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>706947475370708992</td>\n",
       "      <td>12489602</td>\n",
       "      <td>Jake the Negative</td>\n",
       "      <td>JakeTheX</td>\n",
       "      <td>Mon Mar 07 20:59:47 +0000 2016</td>\n",
       "      <td>Stuck on a train outside Mordialloc for 10 min...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>706947418911170560</td>\n",
       "      <td>239617252</td>\n",
       "      <td>sweetB</td>\n",
       "      <td>Biancahatesyouu</td>\n",
       "      <td>Mon Mar 07 20:59:33 +0000 2016</td>\n",
       "      <td>@metrotrains how many defective trains do you ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>706946901778665473</td>\n",
       "      <td>255760971</td>\n",
       "      <td>Sean Armstrong</td>\n",
       "      <td>SeanA6</td>\n",
       "      <td>Mon Mar 07 20:57:30 +0000 2016</td>\n",
       "      <td>@metrotrains skipping the loop again so you ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>706946869339893760</td>\n",
       "      <td>2489812628</td>\n",
       "      <td>Ana Tandoc</td>\n",
       "      <td>anatee20</td>\n",
       "      <td>Mon Mar 07 20:57:22 +0000 2016</td>\n",
       "      <td>TWO FAULTY PAKENHAM TRAINS IN ROW IN PEAK HOUR...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2316</th>\n",
       "      <td>706946608789790720</td>\n",
       "      <td>613362313</td>\n",
       "      <td>Yoongi-baby</td>\n",
       "      <td>yoongibaby</td>\n",
       "      <td>Mon Mar 07 20:56:20 +0000 2016</td>\n",
       "      <td>7.35 Carrum stuck between aspendale and mordi....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2317</th>\n",
       "      <td>706946199421489152</td>\n",
       "      <td>78862399</td>\n",
       "      <td>regan</td>\n",
       "      <td>regan_23</td>\n",
       "      <td>Mon Mar 07 20:54:43 +0000 2016</td>\n",
       "      <td>@metrotrains why is the 7.47 Frankston to Flin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2318</th>\n",
       "      <td>706946193985671168</td>\n",
       "      <td>744925238</td>\n",
       "      <td>A.G.Pickersgill</td>\n",
       "      <td>PickersgillAG</td>\n",
       "      <td>Mon Mar 07 20:54:41 +0000 2016</td>\n",
       "      <td>@metrotrains what the is going on with Frankst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2319</th>\n",
       "      <td>706946061693165568</td>\n",
       "      <td>3657454632</td>\n",
       "      <td>Emma</td>\n",
       "      <td>Emma80040653</td>\n",
       "      <td>Mon Mar 07 20:54:10 +0000 2016</td>\n",
       "      <td>@metrotrains what's the deal with the train no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2320</th>\n",
       "      <td>706945466294886401</td>\n",
       "      <td>14506011</td>\n",
       "      <td>Ryan Bigg</td>\n",
       "      <td>ryanbigg</td>\n",
       "      <td>Mon Mar 07 20:51:48 +0000 2016</td>\n",
       "      <td>@metrotrains There’s only like another 8 stati...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2321</th>\n",
       "      <td>706945462914252800</td>\n",
       "      <td>482449754</td>\n",
       "      <td>jeff watkins</td>\n",
       "      <td>jeffw0303</td>\n",
       "      <td>Mon Mar 07 20:51:47 +0000 2016</td>\n",
       "      <td>@metrotrains suggest you dont notify when a tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2322</th>\n",
       "      <td>706945404059803648</td>\n",
       "      <td>20215196</td>\n",
       "      <td>Alexandra Wake</td>\n",
       "      <td>WakeinFright</td>\n",
       "      <td>Mon Mar 07 20:51:33 +0000 2016</td>\n",
       "      <td>Dear #rmitjournos  while I have left a small c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2323</th>\n",
       "      <td>706945041864859650</td>\n",
       "      <td>14506011</td>\n",
       "      <td>Ryan Bigg</td>\n",
       "      <td>ryanbigg</td>\n",
       "      <td>Mon Mar 07 20:50:07 +0000 2016</td>\n",
       "      <td>@metrotrains Good work on meeting 100% passeng...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2324</th>\n",
       "      <td>706944314010513408</td>\n",
       "      <td>102023083</td>\n",
       "      <td>Michael Bell</td>\n",
       "      <td>Xtrackka</td>\n",
       "      <td>Mon Mar 07 20:47:13 +0000 2016</td>\n",
       "      <td>\"Your 7:44am service has been delayed &amp;amp; is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>706944086767316992</td>\n",
       "      <td>3303945158</td>\n",
       "      <td>Somya Jain</td>\n",
       "      <td>somyamelbourne</td>\n",
       "      <td>Mon Mar 07 20:46:19 +0000 2016</td>\n",
       "      <td>@metrotrains is there a reason to why there is...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2326</th>\n",
       "      <td>706942491832889344</td>\n",
       "      <td>398474575</td>\n",
       "      <td>Laura Rouhan</td>\n",
       "      <td>aminotwittyenuf</td>\n",
       "      <td>Mon Mar 07 20:39:59 +0000 2016</td>\n",
       "      <td>@metrotrains 15 min to get from Footscray to S...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2327</th>\n",
       "      <td>706941916269518848</td>\n",
       "      <td>271919597</td>\n",
       "      <td>Aegnor</td>\n",
       "      <td>aegnor79</td>\n",
       "      <td>Mon Mar 07 20:37:41 +0000 2016</td>\n",
       "      <td>Doesn't seem that hard for the train to take y...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2328</th>\n",
       "      <td>706941859780689920</td>\n",
       "      <td>83424356</td>\n",
       "      <td>superjax23</td>\n",
       "      <td>superjax23</td>\n",
       "      <td>Mon Mar 07 20:37:28 +0000 2016</td>\n",
       "      <td>Good work @metrotrains should make this more r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2329</th>\n",
       "      <td>706941411526987777</td>\n",
       "      <td>271919597</td>\n",
       "      <td>Aegnor</td>\n",
       "      <td>aegnor79</td>\n",
       "      <td>Mon Mar 07 20:35:41 +0000 2016</td>\n",
       "      <td>Sharp uptick recently in the number of @metrot...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>706941303813111808</td>\n",
       "      <td>429531027</td>\n",
       "      <td>Wendy Frerichs</td>\n",
       "      <td>WendyFrerichs</td>\n",
       "      <td>Mon Mar 07 20:35:15 +0000 2016</td>\n",
       "      <td>@EllenSceneay @vline_geelong So does @metrotrains</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2331</th>\n",
       "      <td>706940202741141504</td>\n",
       "      <td>89561404</td>\n",
       "      <td>Bhushan Rao</td>\n",
       "      <td>Yourappa</td>\n",
       "      <td>Mon Mar 07 20:30:53 +0000 2016</td>\n",
       "      <td>Some signal issues causing Werribee line train...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2332</th>\n",
       "      <td>706939694601211904</td>\n",
       "      <td>330616036</td>\n",
       "      <td>Kristin Winterfjord</td>\n",
       "      <td>LornaViking</td>\n",
       "      <td>Mon Mar 07 20:28:52 +0000 2016</td>\n",
       "      <td>#Melbourne! Where you must allow an extra hour...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2333</th>\n",
       "      <td>706939669204721664</td>\n",
       "      <td>4088241794</td>\n",
       "      <td>Hurstbridge Line</td>\n",
       "      <td>HurstbridgeLine</td>\n",
       "      <td>Mon Mar 07 20:28:46 +0000 2016</td>\n",
       "      <td>@NotMetroNotify @metrotrains don't you dare ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2334</th>\n",
       "      <td>706938631840108544</td>\n",
       "      <td>259414434</td>\n",
       "      <td>Kaylor Royakkers</td>\n",
       "      <td>tarkynntayte</td>\n",
       "      <td>Mon Mar 07 20:24:38 +0000 2016</td>\n",
       "      <td>@metrotrains another cancelled train on the Pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2335</th>\n",
       "      <td>706938455016607744</td>\n",
       "      <td>274514885</td>\n",
       "      <td>TiNa</td>\n",
       "      <td>tina_covergirl</td>\n",
       "      <td>Mon Mar 07 20:23:56 +0000 2016</td>\n",
       "      <td>@metrotrains why is the air con never on? Just...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2336</th>\n",
       "      <td>706937594496438272</td>\n",
       "      <td>425630840</td>\n",
       "      <td>Trainexpert</td>\n",
       "      <td>Trainexpert</td>\n",
       "      <td>Mon Mar 07 20:20:31 +0000 2016</td>\n",
       "      <td>RT @Camwhite51: @metrotrains how can this keep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2337</th>\n",
       "      <td>706937579334053888</td>\n",
       "      <td>425630840</td>\n",
       "      <td>Trainexpert</td>\n",
       "      <td>Trainexpert</td>\n",
       "      <td>Mon Mar 07 20:20:27 +0000 2016</td>\n",
       "      <td>RT @metrotrains: UPDATE Glen Waverley line: Li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2338</th>\n",
       "      <td>706937243701653504</td>\n",
       "      <td>2949861234</td>\n",
       "      <td>Joshua Ivanyi</td>\n",
       "      <td>jivanyi88</td>\n",
       "      <td>Mon Mar 07 20:19:07 +0000 2016</td>\n",
       "      <td>@metrotrains well that came to an end fairly q...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2339</th>\n",
       "      <td>706934461623959553</td>\n",
       "      <td>3308204684</td>\n",
       "      <td>PTV HUB</td>\n",
       "      <td>PTVHUB</td>\n",
       "      <td>Mon Mar 07 20:08:04 +0000 2016</td>\n",
       "      <td>@vline_ballarat maybe it's time that @metrotra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2340</th>\n",
       "      <td>706930884335652865</td>\n",
       "      <td>368662384</td>\n",
       "      <td>Leeyong Soo</td>\n",
       "      <td>Leeyong_Soo</td>\n",
       "      <td>Mon Mar 07 19:53:51 +0000 2016</td>\n",
       "      <td>Does the GW line even run any more @metrotrain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2341</th>\n",
       "      <td>706930446144131072</td>\n",
       "      <td>4088241794</td>\n",
       "      <td>Hurstbridge Line</td>\n",
       "      <td>HurstbridgeLine</td>\n",
       "      <td>Mon Mar 07 19:52:07 +0000 2016</td>\n",
       "      <td>RT @blacklmb: Desperately need more services o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2342 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      id     user_id            user_name       user_sname  \\\n",
       "0     710240637497380864   534729059        Luke Sabatini    luke_sabatini   \n",
       "1     710240382311731200   215322466       Sina Marandian          myCroon   \n",
       "2     710239778554257408   947522706        Brett Keleher  thebrickcleaner   \n",
       "3     710238746688364545   215322466       Sina Marandian          myCroon   \n",
       "4     710238698428706816    94544311                  Ant           AntB77   \n",
       "5     710237588318085120    94544311                  Ant           AntB77   \n",
       "6     710234915384590336   310818887            Brad Cook         PkmtBrad   \n",
       "7     710233767881748480   182766018          Mark Stilve          stilves   \n",
       "8     710232721625206784   387479230                Emily          emtoone   \n",
       "9     710229717870186496    93570145    Fake Metro Trains  fakemetrotrains   \n",
       "10    710226759044562944    24331633              esayche          esayche   \n",
       "11    710226086659895297    93570145    Fake Metro Trains  fakemetrotrains   \n",
       "12    710225750482223104  2849186803              allyboo  littlesandieago   \n",
       "13    710224901131505664  3254244876          Megh Shetty        Megshetty   \n",
       "14    710222822719639552  2440721072          Kat Ritchie      kattritchie   \n",
       "15    710221833757298688  3308204684              PTV HUB           PTVHUB   \n",
       "16    710221762424733696  3308204684              PTV HUB           PTVHUB   \n",
       "17    710221042837381121    59771697             Guru Rao          raoguru   \n",
       "18    710220563029950464   397171390         Rhiannon Rak   rhiannonkatexo   \n",
       "19    710220278547087360    94444054     Bobby Przesmycki         bolekprz   \n",
       "20    710218790856839168   489088556          Biren Joshi       JoshiBiren   \n",
       "21    710218105033662464   718022906         Matthew John     thethorpstar   \n",
       "22    710217951077486592  1591227588         clear qualia       aspicacity   \n",
       "23    710217846572261376   138196049     Suburban Tourism        NoHeDaily   \n",
       "24    710217581584457728   320078797      Lissanne Oliver   LissanneOliver   \n",
       "25    710217553524563968     8303822         Daniel Bowen      danielbowen   \n",
       "26    710217542292213761    93570145    Fake Metro Trains  fakemetrotrains   \n",
       "27    710217290562703360    26199526         Dan Nicholas           nnwave   \n",
       "28    710217227857858560   324890519                Amzzz          amzzz13   \n",
       "29    710216956247298048   489088556          Biren Joshi       JoshiBiren   \n",
       "...                  ...         ...                  ...              ...   \n",
       "2312  706947475370708992    12489602    Jake the Negative         JakeTheX   \n",
       "2313  706947418911170560   239617252               sweetB  Biancahatesyouu   \n",
       "2314  706946901778665473   255760971       Sean Armstrong           SeanA6   \n",
       "2315  706946869339893760  2489812628           Ana Tandoc         anatee20   \n",
       "2316  706946608789790720   613362313          Yoongi-baby       yoongibaby   \n",
       "2317  706946199421489152    78862399                regan         regan_23   \n",
       "2318  706946193985671168   744925238      A.G.Pickersgill    PickersgillAG   \n",
       "2319  706946061693165568  3657454632                 Emma     Emma80040653   \n",
       "2320  706945466294886401    14506011            Ryan Bigg         ryanbigg   \n",
       "2321  706945462914252800   482449754         jeff watkins        jeffw0303   \n",
       "2322  706945404059803648    20215196       Alexandra Wake     WakeinFright   \n",
       "2323  706945041864859650    14506011            Ryan Bigg         ryanbigg   \n",
       "2324  706944314010513408   102023083         Michael Bell         Xtrackka   \n",
       "2325  706944086767316992  3303945158           Somya Jain   somyamelbourne   \n",
       "2326  706942491832889344   398474575         Laura Rouhan  aminotwittyenuf   \n",
       "2327  706941916269518848   271919597               Aegnor         aegnor79   \n",
       "2328  706941859780689920    83424356           superjax23       superjax23   \n",
       "2329  706941411526987777   271919597               Aegnor         aegnor79   \n",
       "2330  706941303813111808   429531027       Wendy Frerichs    WendyFrerichs   \n",
       "2331  706940202741141504    89561404          Bhushan Rao         Yourappa   \n",
       "2332  706939694601211904   330616036  Kristin Winterfjord      LornaViking   \n",
       "2333  706939669204721664  4088241794     Hurstbridge Line  HurstbridgeLine   \n",
       "2334  706938631840108544   259414434     Kaylor Royakkers     tarkynntayte   \n",
       "2335  706938455016607744   274514885                 TiNa   tina_covergirl   \n",
       "2336  706937594496438272   425630840          Trainexpert      Trainexpert   \n",
       "2337  706937579334053888   425630840          Trainexpert      Trainexpert   \n",
       "2338  706937243701653504  2949861234        Joshua Ivanyi        jivanyi88   \n",
       "2339  706934461623959553  3308204684              PTV HUB           PTVHUB   \n",
       "2340  706930884335652865   368662384          Leeyong Soo      Leeyong_Soo   \n",
       "2341  706930446144131072  4088241794     Hurstbridge Line  HurstbridgeLine   \n",
       "\n",
       "                          created_at  \\\n",
       "0     Wed Mar 16 23:05:38 +0000 2016   \n",
       "1     Wed Mar 16 23:04:37 +0000 2016   \n",
       "2     Wed Mar 16 23:02:13 +0000 2016   \n",
       "3     Wed Mar 16 22:58:07 +0000 2016   \n",
       "4     Wed Mar 16 22:57:55 +0000 2016   \n",
       "5     Wed Mar 16 22:53:31 +0000 2016   \n",
       "6     Wed Mar 16 22:42:54 +0000 2016   \n",
       "7     Wed Mar 16 22:38:20 +0000 2016   \n",
       "8     Wed Mar 16 22:34:10 +0000 2016   \n",
       "9     Wed Mar 16 22:22:14 +0000 2016   \n",
       "10    Wed Mar 16 22:10:29 +0000 2016   \n",
       "11    Wed Mar 16 22:07:49 +0000 2016   \n",
       "12    Wed Mar 16 22:06:28 +0000 2016   \n",
       "13    Wed Mar 16 22:03:06 +0000 2016   \n",
       "14    Wed Mar 16 21:54:50 +0000 2016   \n",
       "15    Wed Mar 16 21:50:55 +0000 2016   \n",
       "16    Wed Mar 16 21:50:38 +0000 2016   \n",
       "17    Wed Mar 16 21:47:46 +0000 2016   \n",
       "18    Wed Mar 16 21:45:52 +0000 2016   \n",
       "19    Wed Mar 16 21:44:44 +0000 2016   \n",
       "20    Wed Mar 16 21:38:49 +0000 2016   \n",
       "21    Wed Mar 16 21:36:06 +0000 2016   \n",
       "22    Wed Mar 16 21:35:29 +0000 2016   \n",
       "23    Wed Mar 16 21:35:04 +0000 2016   \n",
       "24    Wed Mar 16 21:34:01 +0000 2016   \n",
       "25    Wed Mar 16 21:33:54 +0000 2016   \n",
       "26    Wed Mar 16 21:33:51 +0000 2016   \n",
       "27    Wed Mar 16 21:32:51 +0000 2016   \n",
       "28    Wed Mar 16 21:32:36 +0000 2016   \n",
       "29    Wed Mar 16 21:31:32 +0000 2016   \n",
       "...                              ...   \n",
       "2312  Mon Mar 07 20:59:47 +0000 2016   \n",
       "2313  Mon Mar 07 20:59:33 +0000 2016   \n",
       "2314  Mon Mar 07 20:57:30 +0000 2016   \n",
       "2315  Mon Mar 07 20:57:22 +0000 2016   \n",
       "2316  Mon Mar 07 20:56:20 +0000 2016   \n",
       "2317  Mon Mar 07 20:54:43 +0000 2016   \n",
       "2318  Mon Mar 07 20:54:41 +0000 2016   \n",
       "2319  Mon Mar 07 20:54:10 +0000 2016   \n",
       "2320  Mon Mar 07 20:51:48 +0000 2016   \n",
       "2321  Mon Mar 07 20:51:47 +0000 2016   \n",
       "2322  Mon Mar 07 20:51:33 +0000 2016   \n",
       "2323  Mon Mar 07 20:50:07 +0000 2016   \n",
       "2324  Mon Mar 07 20:47:13 +0000 2016   \n",
       "2325  Mon Mar 07 20:46:19 +0000 2016   \n",
       "2326  Mon Mar 07 20:39:59 +0000 2016   \n",
       "2327  Mon Mar 07 20:37:41 +0000 2016   \n",
       "2328  Mon Mar 07 20:37:28 +0000 2016   \n",
       "2329  Mon Mar 07 20:35:41 +0000 2016   \n",
       "2330  Mon Mar 07 20:35:15 +0000 2016   \n",
       "2331  Mon Mar 07 20:30:53 +0000 2016   \n",
       "2332  Mon Mar 07 20:28:52 +0000 2016   \n",
       "2333  Mon Mar 07 20:28:46 +0000 2016   \n",
       "2334  Mon Mar 07 20:24:38 +0000 2016   \n",
       "2335  Mon Mar 07 20:23:56 +0000 2016   \n",
       "2336  Mon Mar 07 20:20:31 +0000 2016   \n",
       "2337  Mon Mar 07 20:20:27 +0000 2016   \n",
       "2338  Mon Mar 07 20:19:07 +0000 2016   \n",
       "2339  Mon Mar 07 20:08:04 +0000 2016   \n",
       "2340  Mon Mar 07 19:53:51 +0000 2016   \n",
       "2341  Mon Mar 07 19:52:07 +0000 2016   \n",
       "\n",
       "                                                   text  emoticons  \n",
       "0     .@metrotrains, another day another diverted la...          0  \n",
       "1     @metrotrains 12 mins delay YET AGAIN on Flinde...          0  \n",
       "2     @danielbowen @VLine @jimbob_prod @metrotrains ...          0  \n",
       "3     @metrotrains not sure if guys who run Melbourn...          0  \n",
       "4               @metrotrains and we're away 10 min late          0  \n",
       "5     Amateur hr by @metrotrains  Flinders st, 9:49 ...          0  \n",
       "6     @danielbowen @jimbob_prod @metrotrains @VLine ...          0  \n",
       "7     @metrotrains hope our train driver's day gets ...          0  \n",
       "8     @metrotrains can you ever have trains running ...          0  \n",
       "9     @esayche Thanks for your feedback! Just do wha...          0  \n",
       "10    .@metrotrains should subsidise this for Lilyda...          0  \n",
       "11    @littlesandieago Thanks for your feedback! You...          0  \n",
       "12    @metrotrains Thnx for delivering an express tr...          0  \n",
       "13    @metrotrains very poor service blgrave line. T...          0  \n",
       "14    @metrotrains you'd think you'd be able to resp...          0  \n",
       "15    RT @metrotrains: Werribee line delays: Please ...          0  \n",
       "16    RT @metrotrains: Cranbourne/Pakenham line dela...          0  \n",
       "17    @metrotrains @ptv_official @DanielAndrewsMP th...          0  \n",
       "18    RT @fakemetrotrains: Good morning Melbourne! I...          0  \n",
       "19    @metrotrains is without a doubt is the worst P...          0  \n",
       "20    @ptv_official @metrotrains are worst then conn...          0  \n",
       "21    @metrotrains @CityLinkMelb to cost @DanielAndr...          0  \n",
       "22    RT @fakemetrotrains: Good morning Melbourne! I...          0  \n",
       "23    RT @LissanneOliver: Sweet @metrotrains blokes ...          0  \n",
       "24    Sweet @metrotrains blokes offering hot drinks ...          0  \n",
       "25    @jimbob_prod @metrotrains Seems like odd place...          0  \n",
       "26    @othiSA Thanks for your feedback! We’re so sca...          0  \n",
       "27    @metrotrains 3/3 trains for me this week skipp...          0  \n",
       "28    Train is going direct to flinders and skipping...          0  \n",
       "29    @metrotrains previously connex used to get fro...          0  \n",
       "...                                                 ...        ...  \n",
       "2312  Stuck on a train outside Mordialloc for 10 min...          0  \n",
       "2313  @metrotrains how many defective trains do you ...          0  \n",
       "2314  @metrotrains skipping the loop again so you ca...          0  \n",
       "2315  TWO FAULTY PAKENHAM TRAINS IN ROW IN PEAK HOUR...          0  \n",
       "2316  7.35 Carrum stuck between aspendale and mordi....          0  \n",
       "2317  @metrotrains why is the 7.47 Frankston to Flin...          0  \n",
       "2318  @metrotrains what the is going on with Frankst...          0  \n",
       "2319  @metrotrains what's the deal with the train no...          0  \n",
       "2320  @metrotrains There’s only like another 8 stati...          0  \n",
       "2321  @metrotrains suggest you dont notify when a tr...          0  \n",
       "2322  Dear #rmitjournos  while I have left a small c...          0  \n",
       "2323  @metrotrains Good work on meeting 100% passeng...          0  \n",
       "2324  \"Your 7:44am service has been delayed &amp; is...          0  \n",
       "2325  @metrotrains is there a reason to why there is...          0  \n",
       "2326  @metrotrains 15 min to get from Footscray to S...          0  \n",
       "2327  Doesn't seem that hard for the train to take y...          0  \n",
       "2328  Good work @metrotrains should make this more r...          0  \n",
       "2329  Sharp uptick recently in the number of @metrot...          0  \n",
       "2330  @EllenSceneay @vline_geelong So does @metrotrains          0  \n",
       "2331  Some signal issues causing Werribee line train...          0  \n",
       "2332  #Melbourne! Where you must allow an extra hour...          0  \n",
       "2333  @NotMetroNotify @metrotrains don't you dare ca...          0  \n",
       "2334  @metrotrains another cancelled train on the Pa...          0  \n",
       "2335  @metrotrains why is the air con never on? Just...          0  \n",
       "2336  RT @Camwhite51: @metrotrains how can this keep...          0  \n",
       "2337  RT @metrotrains: UPDATE Glen Waverley line: Li...          0  \n",
       "2338  @metrotrains well that came to an end fairly q...          0  \n",
       "2339  @vline_ballarat maybe it's time that @metrotra...          0  \n",
       "2340  Does the GW line even run any more @metrotrain...          0  \n",
       "2341  RT @blacklmb: Desperately need more services o...          0  \n",
       "\n",
       "[2342 rows x 7 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "emoticon_list = []\n",
    "for tweet in tweets_text:\n",
    "    em = findEmoticons(tweet)\n",
    "    if len(em) is 0:\n",
    "        em = np.nan\n",
    "    emoticon_list.append(em)\n",
    "# tweets_pddf['emoticons'] = emoticon_list\n",
    "tweets_pddf['emoticons'] = 0\n",
    "#view tweet record in the dataframe, which contain at least one emoticon.\n",
    "tweets_pddf.dropna(subset=['emoticons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Tokenizing Tweet Text\n",
    "We have discussed the basic steps in pre-processing text in chapter 1. \n",
    "Can those steps be directly applied to Tweet tokenization?\n",
    "Let's see some examples, using the popular NLTK library to tokenise the following tweet:\n",
    "```\n",
    "u'@HawthornFC Howz this?? \\U0001f4aa\\U0001f3fc #PTV #metrotrains #hawthornalways https://t.co/LECNCiTcN5' \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'HawthornFC', 'Howz', 'this', '?', '?', '💪🏼', '#', 'PTV', '#', 'metrotrains', '#', 'hawthornalways', 'https', ':', '//t.co/LECNCiTcN5']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "tweet = u'@HawthornFC Howz this?? \\U0001f4aa\\U0001f3fc #PTV #metrotrains #hawthornalways https://t.co/LECNCiTcN5'\n",
    "print(nltk.tokenize.word_tokenize(tweet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice some peculiarities that are not captured by the NTLK built-in English tokenizer.\n",
    "For instance, @usernames, emoticons, hash tags and URLs are not recognised as single tokens.\n",
    "\"@HawthornFC\" was split into two parts, i.e., \"@\" and \"HawthornFC\", \n",
    "both emoticons' Unicode strings are put together as one token,\n",
    "and the URL has been split into three parts.\n",
    "Therefore, general-purpose English tokenizers are not applicable to tweets.\n",
    "Furthermore, there is another NTLK built-in tokenizer, which is called `TweetTokenizer`.\n",
    "Let's try it out,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@HawthornFC',\n",
       " 'Howz',\n",
       " 'this',\n",
       " '?',\n",
       " '?',\n",
       " '💪',\n",
       " '🏼',\n",
       " '#PTV',\n",
       " '#metrotrains',\n",
       " '#hawthornalways',\n",
       " 'https://t.co/LECNCiTcN5']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tt = TweetTokenizer()\n",
    "tt.tokenize(tweet) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`TweetTokenizer` tokenizer takes three arguments:\n",
    "* *preserve_case*: By default, it is set to True. If it is set to\n",
    "   False, then the tokenizer will downcase everything except for\n",
    "   emoticons.\n",
    "* *reduce_len*: The tokenizer will replace repeated character sequences of length 3 or greater with sequences of length 3, if it is set to `True`. For example, \"waaaaayyyy\" is going to be repleced with \"waaayyy\", and \"cooooool\"\n",
    "with \"coool\".\n",
    "* *strip_handles*: all the @usernames will be removed if it is set to `True`\n",
    "\n",
    "Is `TweetTokenizer` good enough? It works much better than the general-purpose English tokenizer. \n",
    "It tokenizes @usernames, hashtags and URLs as single tokens. However, Unicode strings for emoticons are still a problem for `TweetTokenizer`.\n",
    "If we would like to preserve @usernames, emoticons, URLs and hash-tags as individual tokens,\n",
    "Let's try the code discussed in Part 2 of [2] with some modification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['💪',\n",
       " '🏼',\n",
       " '@HawthornFC',\n",
       " 'Howz',\n",
       " 'this',\n",
       " '#PTV',\n",
       " '#metrotrains',\n",
       " '#hawthornalways',\n",
       " 'https://t.co/LECNCiTcN5']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_re = r'''(?x)\n",
    "    (?:@[\\w_]+) # matches @username\n",
    "    |(?:\\#+[\\w_]+[\\w\\'_\\-]*[\\w_]+) # matches hash-tags\n",
    "    |http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+ # matches URLs\n",
    "    |(?:(?:\\d+,?)+(?:\\.?\\d+)?) # matches numbers\n",
    "    |(?:[a-z][a-z'\\-_]+[a-z]) # matches words with hyphens and apostrophes \n",
    "    |(?:[\\w_]+) # mathes other words\n",
    "'''\n",
    "\n",
    "def tokenize(s):\n",
    "    tokens = re.findall(emoji.get_emoji_regexp(), s) # first find all the emoticons\n",
    "    tokens += re.findall(token_re, s)\n",
    "    return tokens\n",
    "\n",
    "tokenize(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared with the results given by the general purpose tokenizer and the tweet tokenizer in NLTK, the customised tokenizer gave much better tokenization of the tweet. \n",
    "Please do take a moment to observe those regular expressions to check if you can understand all of them.\n",
    "Note that the tokenizer is probably far from \n",
    "perfect for handling tweets, as the language used in tweets is very informal. \n",
    "Twitter users often use arbitrary abbreviations, repeat letters in words, and so on.\n",
    "It is very challenging to develop a tokenizer that can perfectly tokenize tweets.\n",
    "After tokenizing the tweets, we can use some procedures introduced in Chapter 2 to further customise\n",
    "the list of tokens we are interested in by counting word frequencies, removing stopwords, generating bigram or even \n",
    "n-grams, etc.\n",
    "\n",
    "### 2.3 Pre-processing Tweet for Sentiment Analysis\n",
    "We have been mentioning sentiment analysis since the beginning of this chapter. \n",
    "Now let's have a look at a simple example of \n",
    "how to pre-process tweets for sentiment analysis by adapting the Python code in [5].\n",
    "As in [5], we assume that all the words in tweets should be converted to lower case; all URLs and @username\n",
    "are eliminated by replacing them with \"URL\" and \"at_USER\" respectively; hastags are replaced with the exact name without the hash symbol; and finally remove punctuation at the start and ending of the tweets.\n",
    "The following Python function should implement all the above tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processTweet(tweet):\n",
    "    #Convert to lower case\n",
    "    tweet = tweet.lower()\n",
    "    #remove emoticons\n",
    "    tweet = re.sub(emoji.get_emoji_regexp(),'',tweet)\n",
    "    #Convert www.* or https?://* to URL\n",
    "    tweet = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+))','URL',tweet)\n",
    "    #Convert @username to AT_USER\n",
    "    tweet = re.sub('@[^\\s]+','AT_USER',tweet)\n",
    "    #Remove additional white spaces\n",
    "    tweet = re.sub('[\\s]+', ' ', tweet)\n",
    "    #Replace #username with username\n",
    "    tweet = re.sub(r'#([^\\s]+)', r'\\1', tweet)\\\n",
    "    #trim\n",
    "    tweet = tweet.strip('\\'\"')\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have noticed the regular expression used to replace \"#username\" with \"username\".\n",
    "What does \"r'\\1'\" mean? \n",
    "It indicates a backreference in regular expressions.\n",
    "'\\1' means replacing it with the subtring matched by the first group in the pattern, i.e., '[^\\s]+'.\n",
    "Instead of using a backreference with a sequence number, you can use named groups, such as\n",
    "```python\n",
    "      tweet = re.sub(r'#(?P<name>[^\\s]+)', r'\\g<name>', tweet)\n",
    "```\n",
    "Let's try the function on the tweet we have been using so far as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@HawthornFC Howz this?? 💪🏼 #PTV #metrotrains #hawthornalways https://t.co/LECNCiTcN5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'AT_USER howz this?? ptv metrotrains hawthornalways URL'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tweet)\n",
    "processTweet(tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to generate a good word vector for a sentiment analysis algorithm,\n",
    "we need to filter the tweet words that are not of interest.\n",
    "These words may include stop words, words with repeated letters,\n",
    "words not starting with an alphabet, and so on.\n",
    "Let's start with handling repeating letters.\n",
    "If we set 'reduce_len' to True, `TweetTokenizer` can automatically reduce\n",
    "the number of time a letter repeats in a single token.\n",
    "Here we show you how to do it with regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look for 2 or more repetitions of character and replace with the character itself\n",
    "def replaceTwoOrMore(s):\n",
    "    pattern = re.compile(r\"(.)\\1{1,}\", re.DOTALL)\n",
    "    return pattern.sub(r\"\\1\\1\", s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pattern matches substrings that contain the same letter be repeated at least two times.\n",
    "The `re.DOTALL` flag tells python to make the ‘.’ special character match all characters, including newline characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cool\n",
      "oops\n",
      "good\n",
      "coold\n"
     ]
    }
   ],
   "source": [
    "print(replaceTwoOrMore('cooooool'))\n",
    "print(replaceTwoOrMore('oooooooooops'))\n",
    "print(replaceTwoOrMore('gooooood'))\n",
    "print(replaceTwoOrMore('coooooold'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the `replaceTwoOrMore` function is not perfect. The words recovered by this function do not always have correct lexical forms, such as \"coold\".\n",
    "Mapping \"ill-formed\" out-of-vocabulary words to their standard lexical forms is known as lexical normalization, which\n",
    "is a very challenging research problem in natural language processing.\n",
    "It has similarities with spell checking, but differs in that ill-formedness in tweets for example is often intentional due to the 140-characters limit. \n",
    "If you would like to know more about lexical normalization, you should read the research paper on \"[Lexical Normalisation of Short Text Messages: Makn Sens a #twitter](http://www.aclweb.org/anthology/P11-1038)\" by Bo Han and Timothy Baldwin.\n",
    "Let's now move to removing stopwords from tweets.\n",
    "We will use the same stopword list used in the previous two chapters,\n",
    "and load and store all the stopwords in a Python set object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopwords = []\n",
    "with open('./stopwords_en.txt') as f:\n",
    "    stopwords = f.read().splitlines()\n",
    "stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We further remove punctuation such as comma, single/double quote, question marks at the start and end of each word. For example, \"this??\" will be replaced with \"this\", and remove words starting with non-alphabets, e.g., \"124m\" and \"7.07am\".\n",
    "Put all the code together, we derive the following function for extracting feature words from a tweet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getFeatureVector(tweet):\n",
    "    featureVector = []\n",
    "    #split tweet into words\n",
    "    words = tweet.split()\n",
    "    for w in words:\n",
    "        #replace two or more with two occurrences\n",
    "        w = replaceTwoOrMore(w)\n",
    "        #strip punctuation\n",
    "        w = w.strip('\\'\"?,.')\n",
    "        #check if the word stats with an alphabet\n",
    "        val = re.search(r\"^[a-zA-Z][a-zA-Z0-9]*$\", w)\n",
    "        #ignore if it is a stop word\n",
    "        if(w in stopwords or val is None):\n",
    "            continue\n",
    "        else:\n",
    "            featureVector.append(w.lower())\n",
    "    return featureVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the feature words extracted for the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for t in tweets_text:\n",
    "    print(t)\n",
    "    print(getFeatureVector(processTweet(t)), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to counting the frequencies of emoticons, we can also count the frequencies of words in the pre-processed tweets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+\n",
      "| Words | Count |\n",
      "+-------+-------+\n",
      "+-------+-------+\n"
     ]
    }
   ],
   "source": [
    "f_list = []\n",
    "for t in tweets_text:\n",
    "     f_list += getFeatureVector(processTweet(t))\n",
    "      \n",
    "f_counter = collections.Counter(f_list)\n",
    "\n",
    "pt = PrettyTable(field_names=['Words','Count'])\n",
    "[pt.add_row(kv) for kv in f_counter.most_common()[:10]]\n",
    "\n",
    "pt.align['Words'], pt.align['Count'] = 'l', 'r'\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not surprising that \"train\" was the most frequent word, as all the tweets are about metrotrains.\n",
    "\"rt\" was a very common token, which implies that there were a number of retweets. \n",
    "Finally, let's save the pre-processed tweets as one column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_list = []\n",
    "for tweet in tweets_text:\n",
    "    feature_list.append(getFeatureVector(processTweet(tweet)))\n",
    "\n",
    "# tweets_pddf['feature_words'] = feature_list\n",
    "tweets_pddf['feature_words'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_sname</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>emoticons</th>\n",
       "      <th>feature_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>710240637497380864</td>\n",
       "      <td>534729059</td>\n",
       "      <td>Luke Sabatini</td>\n",
       "      <td>luke_sabatini</td>\n",
       "      <td>Wed Mar 16 23:05:38 +0000 2016</td>\n",
       "      <td>.@metrotrains, another day another diverted la...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>710240382311731200</td>\n",
       "      <td>215322466</td>\n",
       "      <td>Sina Marandian</td>\n",
       "      <td>myCroon</td>\n",
       "      <td>Wed Mar 16 23:04:37 +0000 2016</td>\n",
       "      <td>@metrotrains 12 mins delay YET AGAIN on Flinde...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>710239778554257408</td>\n",
       "      <td>947522706</td>\n",
       "      <td>Brett Keleher</td>\n",
       "      <td>thebrickcleaner</td>\n",
       "      <td>Wed Mar 16 23:02:13 +0000 2016</td>\n",
       "      <td>@danielbowen @VLine @jimbob_prod @metrotrains ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>710238746688364545</td>\n",
       "      <td>215322466</td>\n",
       "      <td>Sina Marandian</td>\n",
       "      <td>myCroon</td>\n",
       "      <td>Wed Mar 16 22:58:07 +0000 2016</td>\n",
       "      <td>@metrotrains not sure if guys who run Melbourn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>710238698428706816</td>\n",
       "      <td>94544311</td>\n",
       "      <td>Ant</td>\n",
       "      <td>AntB77</td>\n",
       "      <td>Wed Mar 16 22:57:55 +0000 2016</td>\n",
       "      <td>@metrotrains and we're away 10 min late</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>710237588318085120</td>\n",
       "      <td>94544311</td>\n",
       "      <td>Ant</td>\n",
       "      <td>AntB77</td>\n",
       "      <td>Wed Mar 16 22:53:31 +0000 2016</td>\n",
       "      <td>Amateur hr by @metrotrains  Flinders st, 9:49 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>710234915384590336</td>\n",
       "      <td>310818887</td>\n",
       "      <td>Brad Cook</td>\n",
       "      <td>PkmtBrad</td>\n",
       "      <td>Wed Mar 16 22:42:54 +0000 2016</td>\n",
       "      <td>@danielbowen @jimbob_prod @metrotrains @VLine ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>710233767881748480</td>\n",
       "      <td>182766018</td>\n",
       "      <td>Mark Stilve</td>\n",
       "      <td>stilves</td>\n",
       "      <td>Wed Mar 16 22:38:20 +0000 2016</td>\n",
       "      <td>@metrotrains hope our train driver's day gets ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>710232721625206784</td>\n",
       "      <td>387479230</td>\n",
       "      <td>Emily</td>\n",
       "      <td>emtoone</td>\n",
       "      <td>Wed Mar 16 22:34:10 +0000 2016</td>\n",
       "      <td>@metrotrains can you ever have trains running ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>710229717870186496</td>\n",
       "      <td>93570145</td>\n",
       "      <td>Fake Metro Trains</td>\n",
       "      <td>fakemetrotrains</td>\n",
       "      <td>Wed Mar 16 22:22:14 +0000 2016</td>\n",
       "      <td>@esayche Thanks for your feedback! Just do wha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>710226759044562944</td>\n",
       "      <td>24331633</td>\n",
       "      <td>esayche</td>\n",
       "      <td>esayche</td>\n",
       "      <td>Wed Mar 16 22:10:29 +0000 2016</td>\n",
       "      <td>.@metrotrains should subsidise this for Lilyda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>710226086659895297</td>\n",
       "      <td>93570145</td>\n",
       "      <td>Fake Metro Trains</td>\n",
       "      <td>fakemetrotrains</td>\n",
       "      <td>Wed Mar 16 22:07:49 +0000 2016</td>\n",
       "      <td>@littlesandieago Thanks for your feedback! You...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>710225750482223104</td>\n",
       "      <td>2849186803</td>\n",
       "      <td>allyboo</td>\n",
       "      <td>littlesandieago</td>\n",
       "      <td>Wed Mar 16 22:06:28 +0000 2016</td>\n",
       "      <td>@metrotrains Thnx for delivering an express tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>710224901131505664</td>\n",
       "      <td>3254244876</td>\n",
       "      <td>Megh Shetty</td>\n",
       "      <td>Megshetty</td>\n",
       "      <td>Wed Mar 16 22:03:06 +0000 2016</td>\n",
       "      <td>@metrotrains very poor service blgrave line. T...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>710222822719639552</td>\n",
       "      <td>2440721072</td>\n",
       "      <td>Kat Ritchie</td>\n",
       "      <td>kattritchie</td>\n",
       "      <td>Wed Mar 16 21:54:50 +0000 2016</td>\n",
       "      <td>@metrotrains you'd think you'd be able to resp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>710221833757298688</td>\n",
       "      <td>3308204684</td>\n",
       "      <td>PTV HUB</td>\n",
       "      <td>PTVHUB</td>\n",
       "      <td>Wed Mar 16 21:50:55 +0000 2016</td>\n",
       "      <td>RT @metrotrains: Werribee line delays: Please ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>710221762424733696</td>\n",
       "      <td>3308204684</td>\n",
       "      <td>PTV HUB</td>\n",
       "      <td>PTVHUB</td>\n",
       "      <td>Wed Mar 16 21:50:38 +0000 2016</td>\n",
       "      <td>RT @metrotrains: Cranbourne/Pakenham line dela...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>710221042837381121</td>\n",
       "      <td>59771697</td>\n",
       "      <td>Guru Rao</td>\n",
       "      <td>raoguru</td>\n",
       "      <td>Wed Mar 16 21:47:46 +0000 2016</td>\n",
       "      <td>@metrotrains @ptv_official @DanielAndrewsMP th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>710220563029950464</td>\n",
       "      <td>397171390</td>\n",
       "      <td>Rhiannon Rak</td>\n",
       "      <td>rhiannonkatexo</td>\n",
       "      <td>Wed Mar 16 21:45:52 +0000 2016</td>\n",
       "      <td>RT @fakemetrotrains: Good morning Melbourne! I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>710220278547087360</td>\n",
       "      <td>94444054</td>\n",
       "      <td>Bobby Przesmycki</td>\n",
       "      <td>bolekprz</td>\n",
       "      <td>Wed Mar 16 21:44:44 +0000 2016</td>\n",
       "      <td>@metrotrains is without a doubt is the worst P...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>710218790856839168</td>\n",
       "      <td>489088556</td>\n",
       "      <td>Biren Joshi</td>\n",
       "      <td>JoshiBiren</td>\n",
       "      <td>Wed Mar 16 21:38:49 +0000 2016</td>\n",
       "      <td>@ptv_official @metrotrains are worst then conn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>710218105033662464</td>\n",
       "      <td>718022906</td>\n",
       "      <td>Matthew John</td>\n",
       "      <td>thethorpstar</td>\n",
       "      <td>Wed Mar 16 21:36:06 +0000 2016</td>\n",
       "      <td>@metrotrains @CityLinkMelb to cost @DanielAndr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>710217951077486592</td>\n",
       "      <td>1591227588</td>\n",
       "      <td>clear qualia</td>\n",
       "      <td>aspicacity</td>\n",
       "      <td>Wed Mar 16 21:35:29 +0000 2016</td>\n",
       "      <td>RT @fakemetrotrains: Good morning Melbourne! I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>710217846572261376</td>\n",
       "      <td>138196049</td>\n",
       "      <td>Suburban Tourism</td>\n",
       "      <td>NoHeDaily</td>\n",
       "      <td>Wed Mar 16 21:35:04 +0000 2016</td>\n",
       "      <td>RT @LissanneOliver: Sweet @metrotrains blokes ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>710217581584457728</td>\n",
       "      <td>320078797</td>\n",
       "      <td>Lissanne Oliver</td>\n",
       "      <td>LissanneOliver</td>\n",
       "      <td>Wed Mar 16 21:34:01 +0000 2016</td>\n",
       "      <td>Sweet @metrotrains blokes offering hot drinks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>710217553524563968</td>\n",
       "      <td>8303822</td>\n",
       "      <td>Daniel Bowen</td>\n",
       "      <td>danielbowen</td>\n",
       "      <td>Wed Mar 16 21:33:54 +0000 2016</td>\n",
       "      <td>@jimbob_prod @metrotrains Seems like odd place...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>710217542292213761</td>\n",
       "      <td>93570145</td>\n",
       "      <td>Fake Metro Trains</td>\n",
       "      <td>fakemetrotrains</td>\n",
       "      <td>Wed Mar 16 21:33:51 +0000 2016</td>\n",
       "      <td>@othiSA Thanks for your feedback! We’re so sca...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>710217290562703360</td>\n",
       "      <td>26199526</td>\n",
       "      <td>Dan Nicholas</td>\n",
       "      <td>nnwave</td>\n",
       "      <td>Wed Mar 16 21:32:51 +0000 2016</td>\n",
       "      <td>@metrotrains 3/3 trains for me this week skipp...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>710217227857858560</td>\n",
       "      <td>324890519</td>\n",
       "      <td>Amzzz</td>\n",
       "      <td>amzzz13</td>\n",
       "      <td>Wed Mar 16 21:32:36 +0000 2016</td>\n",
       "      <td>Train is going direct to flinders and skipping...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>710216956247298048</td>\n",
       "      <td>489088556</td>\n",
       "      <td>Biren Joshi</td>\n",
       "      <td>JoshiBiren</td>\n",
       "      <td>Wed Mar 16 21:31:32 +0000 2016</td>\n",
       "      <td>@metrotrains previously connex used to get fro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>710216866430455809</td>\n",
       "      <td>59771697</td>\n",
       "      <td>Guru Rao</td>\n",
       "      <td>raoguru</td>\n",
       "      <td>Wed Mar 16 21:31:10 +0000 2016</td>\n",
       "      <td>@metrotrains why not u run a train as per sche...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>710216624490414081</td>\n",
       "      <td>3028803219</td>\n",
       "      <td>The Book of Metro</td>\n",
       "      <td>BookOfMetro</td>\n",
       "      <td>Wed Mar 16 21:30:13 +0000 2016</td>\n",
       "      <td>A touch of red did suffuse the Line Informatio...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>710216370525319168</td>\n",
       "      <td>132868605</td>\n",
       "      <td>Kaz Healey</td>\n",
       "      <td>kazhealey</td>\n",
       "      <td>Wed Mar 16 21:29:12 +0000 2016</td>\n",
       "      <td>RT @fakemetrotrains: Good morning Melbourne! I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>710215652527583232</td>\n",
       "      <td>393958473</td>\n",
       "      <td>Jeremy Bugeja</td>\n",
       "      <td>JezBug</td>\n",
       "      <td>Wed Mar 16 21:26:21 +0000 2016</td>\n",
       "      <td>RT @fakemetrotrains: Good morning Melbourne! I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>710215609695350788</td>\n",
       "      <td>35676912</td>\n",
       "      <td>City of Maribyrnong</td>\n",
       "      <td>MaribyrnongCC</td>\n",
       "      <td>Wed Mar 16 21:26:11 +0000 2016</td>\n",
       "      <td>RT @metrotrains: Werribee line delays: Please ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>710214953299390464</td>\n",
       "      <td>3031845428</td>\n",
       "      <td>Melissa Tandy</td>\n",
       "      <td>melissa_tandy</td>\n",
       "      <td>Wed Mar 16 21:23:34 +0000 2016</td>\n",
       "      <td>@metrotrains great idea free coffees at random...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>710214946114502658</td>\n",
       "      <td>155139936</td>\n",
       "      <td>Megan Mitchell</td>\n",
       "      <td>meganetmitchell</td>\n",
       "      <td>Wed Mar 16 21:23:32 +0000 2016</td>\n",
       "      <td>RT @fakemetrotrains: Good morning Melbourne! I...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>710214703872520192</td>\n",
       "      <td>245663474</td>\n",
       "      <td>Amanda Bullock</td>\n",
       "      <td>nettyhawk</td>\n",
       "      <td>Wed Mar 16 21:22:35 +0000 2016</td>\n",
       "      <td>@mmmhotbreakfast surely on a massive weekend i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>710214619025920000</td>\n",
       "      <td>2279805739</td>\n",
       "      <td>Alex</td>\n",
       "      <td>AlexAllylaw</td>\n",
       "      <td>Wed Mar 16 21:22:14 +0000 2016</td>\n",
       "      <td>Hey @metrotrains stickers on handrails to show...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>710214617545347072</td>\n",
       "      <td>94895312</td>\n",
       "      <td>Omar</td>\n",
       "      <td>Omarsette</td>\n",
       "      <td>Wed Mar 16 21:22:14 +0000 2016</td>\n",
       "      <td>Just another city loop service diverted to Fli...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>710214425815306241</td>\n",
       "      <td>19674129</td>\n",
       "      <td>Christopher Welldon</td>\n",
       "      <td>chrisopotamia</td>\n",
       "      <td>Wed Mar 16 21:21:28 +0000 2016</td>\n",
       "      <td>@metrotrains Carriage 97M on the South Morang ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>710214399315685376</td>\n",
       "      <td>36862191</td>\n",
       "      <td>Mark K</td>\n",
       "      <td>mark_melb</td>\n",
       "      <td>Wed Mar 16 21:21:22 +0000 2016</td>\n",
       "      <td>@metrotrains When you say 2-3mins late, do you...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>710214169115537409</td>\n",
       "      <td>3657454632</td>\n",
       "      <td>Emma</td>\n",
       "      <td>Emma80040653</td>\n",
       "      <td>Wed Mar 16 21:20:27 +0000 2016</td>\n",
       "      <td>@metrotrains @tw8_69 @JacintaAllanMP @3AW693 i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>710214149381304320</td>\n",
       "      <td>3028803219</td>\n",
       "      <td>The Book of Metro</td>\n",
       "      <td>BookOfMetro</td>\n",
       "      <td>Wed Mar 16 21:20:23 +0000 2016</td>\n",
       "      <td>The Lord V/Line did seek to subvert the servic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>710214081349701633</td>\n",
       "      <td>489088556</td>\n",
       "      <td>Biren Joshi</td>\n",
       "      <td>JoshiBiren</td>\n",
       "      <td>Wed Mar 16 21:20:06 +0000 2016</td>\n",
       "      <td>@metrotrains consistently late since last week...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>710214080972230656</td>\n",
       "      <td>55503609</td>\n",
       "      <td>Michael George</td>\n",
       "      <td>PdGeorges</td>\n",
       "      <td>Wed Mar 16 21:20:06 +0000 2016</td>\n",
       "      <td>@metrotrains why are the trains so cold? Airco...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>710214056204828673</td>\n",
       "      <td>14639177</td>\n",
       "      <td>Tyrell</td>\n",
       "      <td>tyrellperera</td>\n",
       "      <td>Wed Mar 16 21:20:00 +0000 2016</td>\n",
       "      <td>RT @JoshiBiren: @metrotrains please please tur...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>710213994968010752</td>\n",
       "      <td>3181366183</td>\n",
       "      <td>TW8</td>\n",
       "      <td>tw8_69</td>\n",
       "      <td>Wed Mar 16 21:19:46 +0000 2016</td>\n",
       "      <td>@metrotrains @JacintaAllanMP @3AW693 BOOM righ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>710213855893270528</td>\n",
       "      <td>489088556</td>\n",
       "      <td>Biren Joshi</td>\n",
       "      <td>JoshiBiren</td>\n",
       "      <td>Wed Mar 16 21:19:13 +0000 2016</td>\n",
       "      <td>@metrotrains please please turn on AC on train...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>710213777082351616</td>\n",
       "      <td>3657454632</td>\n",
       "      <td>Emma</td>\n",
       "      <td>Emma80040653</td>\n",
       "      <td>Wed Mar 16 21:18:54 +0000 2016</td>\n",
       "      <td>@metrotrains could have told us 30 mins ago si...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id     user_id            user_name       user_sname  \\\n",
       "0   710240637497380864   534729059        Luke Sabatini    luke_sabatini   \n",
       "1   710240382311731200   215322466       Sina Marandian          myCroon   \n",
       "2   710239778554257408   947522706        Brett Keleher  thebrickcleaner   \n",
       "3   710238746688364545   215322466       Sina Marandian          myCroon   \n",
       "4   710238698428706816    94544311                  Ant           AntB77   \n",
       "5   710237588318085120    94544311                  Ant           AntB77   \n",
       "6   710234915384590336   310818887            Brad Cook         PkmtBrad   \n",
       "7   710233767881748480   182766018          Mark Stilve          stilves   \n",
       "8   710232721625206784   387479230                Emily          emtoone   \n",
       "9   710229717870186496    93570145    Fake Metro Trains  fakemetrotrains   \n",
       "10  710226759044562944    24331633              esayche          esayche   \n",
       "11  710226086659895297    93570145    Fake Metro Trains  fakemetrotrains   \n",
       "12  710225750482223104  2849186803              allyboo  littlesandieago   \n",
       "13  710224901131505664  3254244876          Megh Shetty        Megshetty   \n",
       "14  710222822719639552  2440721072          Kat Ritchie      kattritchie   \n",
       "15  710221833757298688  3308204684              PTV HUB           PTVHUB   \n",
       "16  710221762424733696  3308204684              PTV HUB           PTVHUB   \n",
       "17  710221042837381121    59771697             Guru Rao          raoguru   \n",
       "18  710220563029950464   397171390         Rhiannon Rak   rhiannonkatexo   \n",
       "19  710220278547087360    94444054     Bobby Przesmycki         bolekprz   \n",
       "20  710218790856839168   489088556          Biren Joshi       JoshiBiren   \n",
       "21  710218105033662464   718022906         Matthew John     thethorpstar   \n",
       "22  710217951077486592  1591227588         clear qualia       aspicacity   \n",
       "23  710217846572261376   138196049     Suburban Tourism        NoHeDaily   \n",
       "24  710217581584457728   320078797      Lissanne Oliver   LissanneOliver   \n",
       "25  710217553524563968     8303822         Daniel Bowen      danielbowen   \n",
       "26  710217542292213761    93570145    Fake Metro Trains  fakemetrotrains   \n",
       "27  710217290562703360    26199526         Dan Nicholas           nnwave   \n",
       "28  710217227857858560   324890519                Amzzz          amzzz13   \n",
       "29  710216956247298048   489088556          Biren Joshi       JoshiBiren   \n",
       "30  710216866430455809    59771697             Guru Rao          raoguru   \n",
       "31  710216624490414081  3028803219    The Book of Metro      BookOfMetro   \n",
       "32  710216370525319168   132868605           Kaz Healey        kazhealey   \n",
       "33  710215652527583232   393958473        Jeremy Bugeja           JezBug   \n",
       "34  710215609695350788    35676912  City of Maribyrnong    MaribyrnongCC   \n",
       "35  710214953299390464  3031845428        Melissa Tandy    melissa_tandy   \n",
       "36  710214946114502658   155139936       Megan Mitchell  meganetmitchell   \n",
       "37  710214703872520192   245663474       Amanda Bullock        nettyhawk   \n",
       "38  710214619025920000  2279805739                 Alex      AlexAllylaw   \n",
       "39  710214617545347072    94895312                 Omar        Omarsette   \n",
       "40  710214425815306241    19674129  Christopher Welldon    chrisopotamia   \n",
       "41  710214399315685376    36862191               Mark K        mark_melb   \n",
       "42  710214169115537409  3657454632                 Emma     Emma80040653   \n",
       "43  710214149381304320  3028803219    The Book of Metro      BookOfMetro   \n",
       "44  710214081349701633   489088556          Biren Joshi       JoshiBiren   \n",
       "45  710214080972230656    55503609       Michael George        PdGeorges   \n",
       "46  710214056204828673    14639177               Tyrell     tyrellperera   \n",
       "47  710213994968010752  3181366183                  TW8           tw8_69   \n",
       "48  710213855893270528   489088556          Biren Joshi       JoshiBiren   \n",
       "49  710213777082351616  3657454632                 Emma     Emma80040653   \n",
       "\n",
       "                        created_at  \\\n",
       "0   Wed Mar 16 23:05:38 +0000 2016   \n",
       "1   Wed Mar 16 23:04:37 +0000 2016   \n",
       "2   Wed Mar 16 23:02:13 +0000 2016   \n",
       "3   Wed Mar 16 22:58:07 +0000 2016   \n",
       "4   Wed Mar 16 22:57:55 +0000 2016   \n",
       "5   Wed Mar 16 22:53:31 +0000 2016   \n",
       "6   Wed Mar 16 22:42:54 +0000 2016   \n",
       "7   Wed Mar 16 22:38:20 +0000 2016   \n",
       "8   Wed Mar 16 22:34:10 +0000 2016   \n",
       "9   Wed Mar 16 22:22:14 +0000 2016   \n",
       "10  Wed Mar 16 22:10:29 +0000 2016   \n",
       "11  Wed Mar 16 22:07:49 +0000 2016   \n",
       "12  Wed Mar 16 22:06:28 +0000 2016   \n",
       "13  Wed Mar 16 22:03:06 +0000 2016   \n",
       "14  Wed Mar 16 21:54:50 +0000 2016   \n",
       "15  Wed Mar 16 21:50:55 +0000 2016   \n",
       "16  Wed Mar 16 21:50:38 +0000 2016   \n",
       "17  Wed Mar 16 21:47:46 +0000 2016   \n",
       "18  Wed Mar 16 21:45:52 +0000 2016   \n",
       "19  Wed Mar 16 21:44:44 +0000 2016   \n",
       "20  Wed Mar 16 21:38:49 +0000 2016   \n",
       "21  Wed Mar 16 21:36:06 +0000 2016   \n",
       "22  Wed Mar 16 21:35:29 +0000 2016   \n",
       "23  Wed Mar 16 21:35:04 +0000 2016   \n",
       "24  Wed Mar 16 21:34:01 +0000 2016   \n",
       "25  Wed Mar 16 21:33:54 +0000 2016   \n",
       "26  Wed Mar 16 21:33:51 +0000 2016   \n",
       "27  Wed Mar 16 21:32:51 +0000 2016   \n",
       "28  Wed Mar 16 21:32:36 +0000 2016   \n",
       "29  Wed Mar 16 21:31:32 +0000 2016   \n",
       "30  Wed Mar 16 21:31:10 +0000 2016   \n",
       "31  Wed Mar 16 21:30:13 +0000 2016   \n",
       "32  Wed Mar 16 21:29:12 +0000 2016   \n",
       "33  Wed Mar 16 21:26:21 +0000 2016   \n",
       "34  Wed Mar 16 21:26:11 +0000 2016   \n",
       "35  Wed Mar 16 21:23:34 +0000 2016   \n",
       "36  Wed Mar 16 21:23:32 +0000 2016   \n",
       "37  Wed Mar 16 21:22:35 +0000 2016   \n",
       "38  Wed Mar 16 21:22:14 +0000 2016   \n",
       "39  Wed Mar 16 21:22:14 +0000 2016   \n",
       "40  Wed Mar 16 21:21:28 +0000 2016   \n",
       "41  Wed Mar 16 21:21:22 +0000 2016   \n",
       "42  Wed Mar 16 21:20:27 +0000 2016   \n",
       "43  Wed Mar 16 21:20:23 +0000 2016   \n",
       "44  Wed Mar 16 21:20:06 +0000 2016   \n",
       "45  Wed Mar 16 21:20:06 +0000 2016   \n",
       "46  Wed Mar 16 21:20:00 +0000 2016   \n",
       "47  Wed Mar 16 21:19:46 +0000 2016   \n",
       "48  Wed Mar 16 21:19:13 +0000 2016   \n",
       "49  Wed Mar 16 21:18:54 +0000 2016   \n",
       "\n",
       "                                                 text  emoticons  \\\n",
       "0   .@metrotrains, another day another diverted la...          0   \n",
       "1   @metrotrains 12 mins delay YET AGAIN on Flinde...          0   \n",
       "2   @danielbowen @VLine @jimbob_prod @metrotrains ...          0   \n",
       "3   @metrotrains not sure if guys who run Melbourn...          0   \n",
       "4             @metrotrains and we're away 10 min late          0   \n",
       "5   Amateur hr by @metrotrains  Flinders st, 9:49 ...          0   \n",
       "6   @danielbowen @jimbob_prod @metrotrains @VLine ...          0   \n",
       "7   @metrotrains hope our train driver's day gets ...          0   \n",
       "8   @metrotrains can you ever have trains running ...          0   \n",
       "9   @esayche Thanks for your feedback! Just do wha...          0   \n",
       "10  .@metrotrains should subsidise this for Lilyda...          0   \n",
       "11  @littlesandieago Thanks for your feedback! You...          0   \n",
       "12  @metrotrains Thnx for delivering an express tr...          0   \n",
       "13  @metrotrains very poor service blgrave line. T...          0   \n",
       "14  @metrotrains you'd think you'd be able to resp...          0   \n",
       "15  RT @metrotrains: Werribee line delays: Please ...          0   \n",
       "16  RT @metrotrains: Cranbourne/Pakenham line dela...          0   \n",
       "17  @metrotrains @ptv_official @DanielAndrewsMP th...          0   \n",
       "18  RT @fakemetrotrains: Good morning Melbourne! I...          0   \n",
       "19  @metrotrains is without a doubt is the worst P...          0   \n",
       "20  @ptv_official @metrotrains are worst then conn...          0   \n",
       "21  @metrotrains @CityLinkMelb to cost @DanielAndr...          0   \n",
       "22  RT @fakemetrotrains: Good morning Melbourne! I...          0   \n",
       "23  RT @LissanneOliver: Sweet @metrotrains blokes ...          0   \n",
       "24  Sweet @metrotrains blokes offering hot drinks ...          0   \n",
       "25  @jimbob_prod @metrotrains Seems like odd place...          0   \n",
       "26  @othiSA Thanks for your feedback! We’re so sca...          0   \n",
       "27  @metrotrains 3/3 trains for me this week skipp...          0   \n",
       "28  Train is going direct to flinders and skipping...          0   \n",
       "29  @metrotrains previously connex used to get fro...          0   \n",
       "30  @metrotrains why not u run a train as per sche...          0   \n",
       "31  A touch of red did suffuse the Line Informatio...          0   \n",
       "32  RT @fakemetrotrains: Good morning Melbourne! I...          0   \n",
       "33  RT @fakemetrotrains: Good morning Melbourne! I...          0   \n",
       "34  RT @metrotrains: Werribee line delays: Please ...          0   \n",
       "35  @metrotrains great idea free coffees at random...          0   \n",
       "36  RT @fakemetrotrains: Good morning Melbourne! I...          0   \n",
       "37  @mmmhotbreakfast surely on a massive weekend i...          0   \n",
       "38  Hey @metrotrains stickers on handrails to show...          0   \n",
       "39  Just another city loop service diverted to Fli...          0   \n",
       "40  @metrotrains Carriage 97M on the South Morang ...          0   \n",
       "41  @metrotrains When you say 2-3mins late, do you...          0   \n",
       "42  @metrotrains @tw8_69 @JacintaAllanMP @3AW693 i...          0   \n",
       "43  The Lord V/Line did seek to subvert the servic...          0   \n",
       "44  @metrotrains consistently late since last week...          0   \n",
       "45  @metrotrains why are the trains so cold? Airco...          0   \n",
       "46  RT @JoshiBiren: @metrotrains please please tur...          0   \n",
       "47  @metrotrains @JacintaAllanMP @3AW693 BOOM righ...          0   \n",
       "48  @metrotrains please please turn on AC on train...          0   \n",
       "49  @metrotrains could have told us 30 mins ago si...          0   \n",
       "\n",
       "    feature_words  \n",
       "0               0  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  \n",
       "5               0  \n",
       "6               0  \n",
       "7               0  \n",
       "8               0  \n",
       "9               0  \n",
       "10              0  \n",
       "11              0  \n",
       "12              0  \n",
       "13              0  \n",
       "14              0  \n",
       "15              0  \n",
       "16              0  \n",
       "17              0  \n",
       "18              0  \n",
       "19              0  \n",
       "20              0  \n",
       "21              0  \n",
       "22              0  \n",
       "23              0  \n",
       "24              0  \n",
       "25              0  \n",
       "26              0  \n",
       "27              0  \n",
       "28              0  \n",
       "29              0  \n",
       "30              0  \n",
       "31              0  \n",
       "32              0  \n",
       "33              0  \n",
       "34              0  \n",
       "35              0  \n",
       "36              0  \n",
       "37              0  \n",
       "38              0  \n",
       "39              0  \n",
       "40              0  \n",
       "41              0  \n",
       "42              0  \n",
       "43              0  \n",
       "44              0  \n",
       "45              0  \n",
       "46              0  \n",
       "47              0  \n",
       "48              0  \n",
       "49              0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_pddf.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 3. Conclusion\n",
    "We started this chapter by learning how to create an authenticated connection and then progressed through a series example code that illustrated how to pre-process tweets and make them ready for analysis.\n",
    "Beside, there are a couple of good tutorials on handling tweets, which are useful for review. They\n",
    "are listed in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 4. Referece reading materials\n",
    "1. \"[Mining Twetter: Exploring Trending Topics, Discovering What People Are Talking About, and More](https://github.com/ptwobrussell/Mining-the-Social-Web-2nd-Edition/blob/master/ipynb/Chapter%201%20-%20Mining%20Twitter.ipynb)\" in \"Mining the Social Web\". 📖 \n",
    "2. \"[Mining Twitter Data with Python](http://marcobonzanini.com/2015/03/02/mining-twitter-data-with-python-part-1/)\", a tutorial by Marco Bonzanini. 📖 \n",
    "3. \"[Twitter API tutorial](http://socialmedia-class.org/twittertutorial.html)\" by Wei Xu, which give a quick tutorial\n",
    "on making API requests through two types of Twitter APIs 📖 \n",
    "4. \"[Sentiment Expression via Emoticons on Social Media](http://arxiv.org/pdf/1511.02556.pdf)\" bu Hao Wang and Jorge A. Castanon (Read this paper is optional)\n",
    "5. \"[How to Build a Twitter Sentiment Analyzer](http://ravikiranj.net/posts/2012/code/how-build-twitter-sentiment-analyzer/)\" by Ravikiran Janardhana. Read two subsections, which are \"Preprocess tweets\" and \"Filtering tweet words\" 📖 .\n",
    "\n",
    "## 5. Exercises\n",
    "1. Extract all the conventional emoticons that are represented by punctuation marks, numbers and letters. Hint: you might need to construct your own regular expressions that can handle the following emoticons: :), :-), :(, :O, :-(, and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
